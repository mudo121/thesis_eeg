{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a raw Dataset\n",
    "This notebook shows the complete pipeline to have machine learning ready data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Masterthesis\\thesis_eeg\\code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# to enable local imports\n",
    "module_path = os.path.abspath('code')\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from machine_learning_data_generation import loadPickeldDataset, processRawDatasetToPickleFiles, loadOnlineEEGdata\n",
    "from consts import DEVICES_NEUROSCAN, DEVICES_MUSE_LSL_OPEN_VIBE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a dataset to pickel files\n",
    "With this function  a dataset gets processed and the output will be saved to pickel files\n",
    "\n",
    "*** Careful! Takes about 1 Hour! ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the config file for muse_lsl_with_open_vibe\n",
      "Skipping openVibe\n",
      "Skipping subject_1\n",
      "#############################################\n",
      "Process Subject subject_10 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/muse_data\\subject_10\\reaction_game_complete.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reiss\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\signal\\spectral.py:1966: UserWarning: nperseg = 1024 is greater than input length  = 512, using nperseg = 512\n",
      "  .format(nperseg, input_length))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "###\n",
      "Extracting Entropy Features...\n",
      "Created Numpy Array - Shape: (298, 1, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\masterthesis\\entropy\\entropy\\entropy.py:180: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n",
      "d:\\masterthesis\\entropy\\entropy\\entropy.py:180: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n",
      "d:\\masterthesis\\entropy\\entropy\\entropy.py:180: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n",
      "d:\\masterthesis\\entropy\\entropy\\entropy.py:180: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing the entropy features...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_10\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_10\\features_frequency_df.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_10\\features_entropy.txt'\n",
      "#############################################\n",
      "Process Subject subject_2 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/muse_data\\subject_2\\reaction_game_complete.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reiss\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\signal\\spectral.py:1966: UserWarning: nperseg = 1024 is greater than input length  = 512, using nperseg = 512\n",
      "  .format(nperseg, input_length))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "###\n",
      "Extracting Entropy Features...\n",
      "Created Numpy Array - Shape: (305, 1, 20)\n",
      "Normalizing the entropy features...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_2\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_2\\features_frequency_df.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_2\\features_entropy.txt'\n",
      "#############################################\n",
      "Process Subject subject_3 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/muse_data\\subject_3\\reaction_game_complete.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reiss\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\signal\\spectral.py:1966: UserWarning: nperseg = 1024 is greater than input length  = 512, using nperseg = 512\n",
      "  .format(nperseg, input_length))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "###\n",
      "Extracting Entropy Features...\n",
      "Created Numpy Array - Shape: (313, 1, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\masterthesis\\entropy\\entropy\\entropy.py:180: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n",
      "d:\\masterthesis\\entropy\\entropy\\entropy.py:180: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing the entropy features...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_3\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_3\\features_frequency_df.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_3\\features_entropy.txt'\n",
      "#############################################\n",
      "Process Subject subject_4 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/muse_data\\subject_4\\reaction_game_complete.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reiss\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\signal\\spectral.py:1966: UserWarning: nperseg = 1024 is greater than input length  = 512, using nperseg = 512\n",
      "  .format(nperseg, input_length))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "###\n",
      "Extracting Entropy Features...\n",
      "Created Numpy Array - Shape: (310, 1, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\masterthesis\\entropy\\entropy\\entropy.py:180: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n",
      "d:\\masterthesis\\entropy\\entropy\\entropy.py:180: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n",
      "d:\\masterthesis\\entropy\\entropy\\entropy.py:180: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n",
      "d:\\masterthesis\\entropy\\entropy\\entropy.py:180: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing the entropy features...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_4\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_4\\features_frequency_df.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/muse_data\\subject_4\\features_entropy.txt'\n",
      "#############################################\n",
      "Process Subject subject_5 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/muse_data\\subject_5\\reaction_game_complete.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reiss\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\signal\\spectral.py:1966: UserWarning: nperseg = 1024 is greater than input length  = 512, using nperseg = 512\n",
      "  .format(nperseg, input_length))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n"
     ]
    },
    {
     "ename": "StatisticsError",
     "evalue": "variance requires at least two data points",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9ecd6dae139f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m                                   \u001b[0mnormalFileName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                                   \u001b[0munlabeledFileName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"reaction_game_complete.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# or 'driving_complete.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                                   skipDirs=['openVibe', 'subject_1', 'subject_6']) # faulty or empty dirs\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Masterthesis\\thesis_eeg\\code\\machine_learning_data_generation.py\u001b[0m in \u001b[0;36mprocessRawDatasetToPickleFiles\u001b[1;34m(datasetDirPath, device, awakeFileName, fatigueFileName, normalFileName, unlabeledFileName, skipDirs)\u001b[0m\n\u001b[0;32m    125\u001b[0m                                                     \u001b[0mfileDir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubjectDir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                                                     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"unlabeled\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                                                     yamlConfig=yamlConfig)\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Masterthesis\\thesis_eeg\\code\\machine_learning_data_generation.py\u001b[0m in \u001b[0;36msafeAndProcessRawFileWithPipeline\u001b[1;34m(rawFilePath, fileDir, label, yamlConfig)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting to process {}...\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawFilePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# process the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mepochSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrequencyFeatureDf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannelNameList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropyArray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropyFeatureList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessRawFileWithPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrawFilePath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myamlConfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myamlConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# save the epoch series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Masterthesis\\thesis_eeg\\code\\machine_learning_data_generation.py\u001b[0m in \u001b[0;36mprocessRawFileWithPipeline\u001b[1;34m(filepath, yamlConfig)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_signal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myamlConfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# general filtering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mepochSeries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_signal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myamlConfig\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# pre-processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mfrequencyFeatureDf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropyArray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropyFeatureList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochSeries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myamlConfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# extract features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mepochSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrequencyFeatureDf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannelNameList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropyArray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropyFeatureList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Masterthesis\\thesis_eeg\\code\\pipelines.py\u001b[0m in \u001b[0;36mfeature_extraction\u001b[1;34m(epochSeries, config)\u001b[0m\n\u001b[0;32m     80\u001b[0m                                                                 numberOfChannels=config['numberOfChannels'], epochSizeCalculation=config['epochSizeCalculation']))\n\u001b[0;32m     81\u001b[0m     ])\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mfreq_feature_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrequency_feature_extraction_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     entropy_feature_extraction_pipeline = Pipeline([\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlast_step\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Masterthesis\\thesis_eeg\\code\\Transformer_Feature_Extraction.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, epochSeries)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m# calculate mean and std dev of everything\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         statisticsBandpowerDict = self.__createStatisticBandpowerDict(channelFrequencyDict = channelFrequencyDict,\n\u001b[1;32m--> 105\u001b[1;33m                                                                       epochSizeCalculation = self.epochSizeCalculation)\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Masterthesis\\thesis_eeg\\code\\Transformer_Feature_Extraction.py\u001b[0m in \u001b[0;36m__createStatisticBandpowerDict\u001b[1;34m(self, channelFrequencyDict, epochSizeCalculation)\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[1;31m# Calculate the standard deviation of the mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m                 bandpower_std_dev = self.__calculateStandardDeviationOverEpochs(valueList = frequencyDict[INDEX_BANDPOWER_LIST],\n\u001b[1;32m--> 337\u001b[1;33m                                                                         numberOfEpochs = epochSizeCalculation)\n\u001b[0m\u001b[0;32m    338\u001b[0m                 \u001b[0mstatisticsBandpowerDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfrequencyBand\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mINDEX_STD_DEV_BANDPOWER_LIST\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbandpower_std_dev\u001b[0m \u001b[1;31m# append it to the dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Masterthesis\\thesis_eeg\\code\\Transformer_Feature_Extraction.py\u001b[0m in \u001b[0;36m__calculateStandardDeviationOverEpochs\u001b[1;34m(self, valueList, numberOfEpochs)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumberOfEpochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalueList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumberOfEpochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalueList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[0mstDev_valueList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnumberOfEpochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\statistics.py\u001b[0m in \u001b[0;36mstdev\u001b[1;34m(data, xbar)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \"\"\"\n\u001b[1;32m--> 649\u001b[1;33m     \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\statistics.py\u001b[0m in \u001b[0;36mvariance\u001b[1;34m(data, xbar)\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mStatisticsError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variance requires at least two data points'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m     \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStatisticsError\u001b[0m: variance requires at least two data points"
     ]
    }
   ],
   "source": [
    "PROCESS_DATA = True\n",
    "\n",
    "\n",
    "if PROCESS_DATA:\n",
    "    # Process the online EEG Data\n",
    "    '''\n",
    "    processRawDatasetToPickleFiles(datasetDirPath = \"D:/Masterthesis/EEG_Data/eeg_data_online\",\n",
    "                              device = DEVICES_NEUROSCAN,\n",
    "                              awakeFileName = None,\n",
    "                              fatigueFileName = \"Fatigue_state_256hz.csv\",\n",
    "                              normalFileName = \"Normal_state_256hz.csv\",\n",
    "                              unlabeledFileName = None)\n",
    "    '''\n",
    "    \n",
    "    # Process the Muse Data\n",
    "    \n",
    "    # Todo add parameter to optionally add en extra name/id to the generated data. E.g. for where it came from (driving, p300, reaction_game, ...)\n",
    "    datasetDirPath = \"D:/Masterthesis/EEG_Data/muse_data\",\n",
    "                                  device = DEVICES_MUSE_LSL_OPEN_VIBE,\n",
    "                                  awakeFileName = None,\n",
    "                                  fatigueFileName = None,\n",
    "                                  normalFileName = None,\n",
    "                                  unlabeledFileName = \"reaction_game_complete.csv\", # or 'driving_complete.csv'\n",
    "                                  skipDirs=['openVibe', 'subject_1', 'subject_6']) # faulty or empty dirs\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print (\"Already processed the EEG Online Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create a Machine Learning Dataset\n",
    "With this functions you can create a X and y Dataset from a given EEG Dataset (use the function 'processRawDatasetToPickleFiles').\n",
    "It creates a X & y for the EEG Signals and the frequency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Subject 1 Data...\n",
      "Load Subject 10 Data...\n",
      "Load Subject 11 Data...\n",
      "Load Subject 12 Data...\n",
      "Load Subject 2 Data...\n",
      "Load Subject 3 Data...\n",
      "Load Subject 4 Data...\n",
      "Load Subject 5 Data...\n",
      "Load Subject 6 Data...\n",
      "Load Subject 7 Data...\n",
      "Load Subject 8 Data...\n",
      "Load Subject 9 Data...\n",
      "Creating Machine Learning Dataset!\n",
      "Processing Subject 1 - Target: NORMAL ...\n",
      "Processing Subject 1 - Target: FATIGUE ...\n",
      "Processing Subject 10 - Target: NORMAL ...\n",
      "Processing Subject 10 - Target: FATIGUE ...\n",
      "Processing Subject 11 - Target: NORMAL ...\n",
      "Processing Subject 11 - Target: FATIGUE ...\n",
      "Processing Subject 12 - Target: NORMAL ...\n",
      "Processing Subject 12 - Target: FATIGUE ...\n",
      "Processing Subject 2 - Target: NORMAL ...\n",
      "Processing Subject 2 - Target: FATIGUE ...\n",
      "Processing Subject 3 - Target: NORMAL ...\n",
      "Processing Subject 3 - Target: FATIGUE ...\n",
      "Processing Subject 4 - Target: NORMAL ...\n",
      "Processing Subject 4 - Target: FATIGUE ...\n",
      "Processing Subject 5 - Target: NORMAL ...\n",
      "Processing Subject 5 - Target: FATIGUE ...\n",
      "Processing Subject 6 - Target: NORMAL ...\n",
      "Processing Subject 6 - Target: FATIGUE ...\n",
      "Processing Subject 7 - Target: NORMAL ...\n",
      "Processing Subject 7 - Target: FATIGUE ...\n",
      "Processing Subject 8 - Target: NORMAL ...\n",
      "Processing Subject 8 - Target: FATIGUE ...\n",
      "Processing Subject 9 - Target: NORMAL ...\n",
      "Processing Subject 9 - Target: FATIGUE ...\n",
      "Done!\n",
      "\n",
      "Saving Machine Learning Dataset into this directory: D:/Masterthesis/EEG_Data/eeg_data_online\n",
      "Saving dict to D:/Masterthesis/EEG_Data/eeg_data_online\\target_labels.txt\n"
     ]
    }
   ],
   "source": [
    "from machine_learning_data_generation import createAndSafeMlDataset\n",
    "from consts import TARGET_FATIGUE, TARGET_NORMAL\n",
    "\n",
    "CREATE_ML_DATA = True\n",
    "\n",
    "TARGET_LABEL_DICT = {TARGET_NORMAL : 1,\n",
    "                     TARGET_FATIGUE : 0}\n",
    "\n",
    "if CREATE_ML_DATA:\n",
    "    \n",
    "    eegDataset = loadPickeldDataset(\"D:/Masterthesis/EEG_Data/eeg_data_online\")\n",
    "    \n",
    "    createAndSafeMlDataset(eegDataset=eegDataset,\n",
    "                           targetLabelDict=TARGET_LABEL_DICT,\n",
    "                           dirPath=\"D:/Masterthesis/EEG_Data/eeg_data_online\")\n",
    "else:\n",
    "    print(\"Already created ML Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - Load  the online EEG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Online EEG Data from D:/Masterthesis/EEG_Data/eeg_data_online ...\n",
      "Data does not get splitted into train and test!\n",
      "EEG Data Shape:\n",
      "(7178, 512, 40) (7178,)\n",
      "Freq Data Shape:\n",
      "(1440, 1, 1200) (1440,)\n",
      "Entropy Data Shape:\n",
      "(7178, 1, 200) (7178,)\n"
     ]
    }
   ],
   "source": [
    "eegData, freqData, entropyData = loadOnlineEEGdata(shuffle=False, splitData=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8c524fd0ec16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape train X: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape train y: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape test X: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape test y: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Shape train X: {}\".format(trainX.shape))\n",
    "print(\"Shape train y: {}\".format(trainy.shape))\n",
    "print(\"Shape test X: {}\".format(testX.shape))\n",
    "print(\"Shape test y: {}\".format(testy.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.58857225, -0.05947701,  0.75340673, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.77181281,  0.53140419,  0.83882233, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.60697763,  0.44422637,  0.88404084, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.73472731,  0.54010546,  0.80864854, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.50687363,  0.31490547,  0.60680156, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.53433675,  0.39765327,  0.74250543, ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#1: 51.620\n",
      ">#2: 51.620\n",
      ">#3: 51.620\n",
      ">#4: 51.620\n",
      ">#5: 51.620\n",
      "[51.62037014961243, 51.62037014961243, 51.62037014961243, 51.62037014961243, 51.62037014961243]\n",
      "Accuracy: 51.620% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "repeats = 5\n",
    "# repeat experiment\n",
    "scores = list()\n",
    "for r in range(repeats):\n",
    "    score = evaluate_model(trainX, trainy, testX, testy)\n",
    "    score = score * 100.0\n",
    "    print('>#%d: %.3f' % (r+1, score))\n",
    "    scores.append(score)\n",
    "# summarize results\n",
    "summarize_results(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
