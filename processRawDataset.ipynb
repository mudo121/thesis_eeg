{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook shows how a raw Dataset gets processed for further machine learning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Masterthesis\\thesis_eeg\\code\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# to enable local imports\n",
    "module_path = os.path.abspath('code')\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from machine_learning_data_generation import loadPickeldDataset\n",
    "from consts import TARGET_LABEL_DICT, DEVICES_NEUROSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a dataset to pickel files\n",
    "With this function  a dataset gets processed and the output will be saved to pickel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed the EEG Online Data\n"
     ]
    }
   ],
   "source": [
    "PROCESS_DATA = False\n",
    "\n",
    "if PROCESS_DATA:\n",
    "    # Process the online EEG Data\n",
    "    processRawDatasetToPickleFiles(datasetDirPath = \"D:/Masterthesis/EEG_Data/eeg_data_online\",\n",
    "                              device = DEVICES_NEUROSCAN,\n",
    "                              awakeFileName = None,\n",
    "                              fatigueFileName = \"Fatigue_state_256hz.csv\",\n",
    "                              normalFileName = \"Normal_state_256hz.csv\",\n",
    "                              unlabeledFileName = None)\n",
    "else:\n",
    "    print (\"Already processed the EEG Online Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create a Machine Learning Dataset\n",
    "With this functions you can create a X and y Dataset from a given EEG Dataset (use the function 'processRawDatasetToPickleFiles')\n",
    "\n",
    "**Todo - Create X und Y for feature DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already created ML Data\n"
     ]
    }
   ],
   "source": [
    "CREATE_ML_DATA = False\n",
    "\n",
    "if CREATE_ML_DATA:\n",
    "    \n",
    "    eegDataset = loadPickeldDataset(\"D:/Masterthesis/EEG_Data/eeg_data_online\")\n",
    "    \n",
    "    createAndSafeMlDataset(eegDataset=eegDataset,\n",
    "                           targetLabelDict=TARGET_LABEL_DICT,\n",
    "                           dirPath=\"D:/Masterthesis/EEG_Data/eeg_data_online\")\n",
    "else:\n",
    "    print(\"Already created ML Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - Load  the online EEG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def convertFeatureDfToXy(featureDf : pd.DataFrame, target : int) -> (np.ndarray, np.ndarray):\n",
    "    samples = []\n",
    "    targetArray = []\n",
    "    \n",
    "    for index, row in featureDf.iterrows():\n",
    "        timesteps = []\n",
    "        features = row.to_numpy() # features\n",
    "        timesteps.append(features)\n",
    "        samples.append(timesteps)\n",
    "        \n",
    "        targetArray.append(target)\n",
    "    \n",
    "    X = np.array(samples)\n",
    "    y = np.array(targetArray)\n",
    "    \n",
    "    return X, y \n",
    "    \n",
    "def loadOnlineEEGdata(test_size=0.3, shuffle=False):\n",
    "    dirPath = \"D:/Masterthesis/EEG_Data/eeg_data_online\"\n",
    "    \n",
    "    print(\"Loading Online EEG Data from {} ...\".format(dirPath))\n",
    "    \n",
    "    # load array\n",
    "    X = np.load(os.path.join(dirPath, 'data_series_X.npy'))\n",
    "    y = np.load(os.path.join(dirPath, 'data_series_y.npy'))\n",
    "    \n",
    "    # load target labels\n",
    "    \n",
    "    # load feature names\n",
    "    \n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state=109, shuffle=shuffle) # 70% training and 30% test\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Online EEG Data from D:/Masterthesis/EEG_Data/eeg_data_online...\n",
      "(5024, 512, 40) (5024, 2) (2154, 512, 40) (2154, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = loadOnlineEEGdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5024, 512)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dstack(np.dstack(X_train))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2154, 512)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dstack(np.dstack(X_test)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5024, 512)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_test[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 15, 64\n",
    "    \n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "        \n",
    "    print(\"n_timesteps: {} - n_features: {} - n_outputs: {}\".format(n_timesteps, n_features, n_outputs))\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = np.mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10, channel=None):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy = loadOnlineEEGdata()\n",
    "    \n",
    "    if channel != None:\n",
    "        print(\"Using only Channel: {}\".format(channel))\n",
    "        trainX = np.dstack(np.dstack(trainX))[channel]\n",
    "        testX = np.dstack(np.dstack(testX))[channel]\n",
    "    \n",
    "    print(\"Loaded the Dataset\")\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_experiment(repeats=1, channel=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Online EEG Data from D:/Masterthesis/EEG_Data/eeg_data_online...\n",
      "(5024, 512, 40) (5024, 2) (2154, 512, 40) (2154, 2)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = loadOnlineEEGdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 5\n",
    "#trainX = np.dstack(np.dstack(trainX))[channel]\n",
    "#testX = np.dstack(np.dstack(testX))[channel]\n",
    "trainX = trainX[:, :, channel:channel+1]\n",
    "testX = testX[:, :, channel:channel+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5024, 512, 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape trainX: (5024, 512, 1)\n",
      "Shape testX: (2154, 512, 1)\n",
      "n_timesteps: 512 - n_features: 1 - n_outputs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-May-20 11:43:31 | WARNING | From C:\\Users\\reiss\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#1: 44.475\n",
      "[44.47539448738098]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-8439c6c4749f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# summarize results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0msummarize_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-119-4b7eab3176db>\u001b[0m in \u001b[0;36msummarize_results\u001b[1;34m(scores)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msummarize_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy: %.3f%% (+/-%.3f)'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Shape trainX: {}\".format(trainX.shape))\n",
    "print(\"Shape testX: {}\".format(testX.shape))\n",
    "\n",
    "repeats = 1\n",
    "# repeat experiment\n",
    "scores = list()\n",
    "for r in range(repeats):\n",
    "    score = evaluate_model(trainX, trainy, testX, testy)\n",
    "    score = score * 100.0\n",
    "    print('>#%d: %.3f' % (r+1, score))\n",
    "    scores.append(score)\n",
    "# summarize results\n",
    "summarize_results(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
