{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook shows how a raw Dataset gets processed for further machine learning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "# to enable local imports\n",
    "module_path = os.path.abspath(os.path.join('code'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import readFileCSV, loadConfigFile\n",
    "from pipelines import (filter_signal, pre_process_signal, feature_extraction, convert_data)\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def saveFeatureListToFile(featureList : List, filepath : str):\n",
    "    \n",
    "    if type(featureList) is not list:\n",
    "        raise Exception(\"The given feature list is not a list!\")\n",
    "    \n",
    "    print(\"Saving a feature list to: '{}'\".format(filepath))\n",
    "    \n",
    "    f = open(filepath, \"w\")\n",
    "    for feature in featureList:\n",
    "        line = \"{}\\n\".format(feature)\n",
    "        f.write(line)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "def processRawFileWithPipeline(filepath : str, yamlConfig) -> (pd.Series, pd.DataFrame, List[str]):\n",
    "    ''' Process a given filepath with the current pipelines \n",
    "    \n",
    "    This creates two different data objects:\n",
    "        epochSeries: This is a panda.Series which contains dataframes. Each index at the series represens one epoch\n",
    "        frequencyFreatureDf: This is a dataframe of the frequency features of the epochSeries. The index represnts the epochs. The features are the columns\n",
    "    '''\n",
    "    if not os.path.isfile(filepath):\n",
    "        raise Exception(\"The file '{}' does not exists!\".format(filepath))\n",
    "    \n",
    "    df = readFileCSV(filepath)\n",
    "    df, channelNameList =  convert_data(df=df, config=yamlConfig, starttime=None)\n",
    "    df = filter_signal(df=df, config=yamlConfig) # general filtering\n",
    "    epochSeries = pre_process_signal(df=df, config=yamlConfig)   # pre-processing\n",
    "    frequencyFeatureDf = feature_extraction(epochSeries=epochSeries, config=yamlConfig) # extract features\n",
    "    \n",
    "    return epochSeries, frequencyFeatureDf, channelNameList\n",
    "\n",
    "def safeAndProcessRawFileWithPipeline(rawFilePath : str, fileDir : str, label : str, yamlConfig):\n",
    "    ''' Process the given rawfilePath and safe the result as pickle files\n",
    "    This function calls 'processRawFileWithPipeline()' and the two returning data objects will be safed\n",
    "    \n",
    "    @param str rawFilePath: path to file which gets process\n",
    "    @param str fileDir: Directory where the data objects should be stored\n",
    "    @param str label: A label to know which data we process, e.g. fatigue, normal or awake data\n",
    "    @param yamlConfig: A loaded yaml config file for processing the data\n",
    "    '''\n",
    "    print (\"Starting to process {}...\".format(rawFilePath))\n",
    "    # process the file\n",
    "    epochSeries, frequencyFeatureDf, channelNameList = processRawFileWithPipeline(filepath=rawFilePath, yamlConfig=yamlConfig)\n",
    "    \n",
    "    # save the epoch series\n",
    "    epochSeries.to_pickle(os.path.join(fileDir,'epochSeries_{}.pkl'.format(label)))\n",
    "    \n",
    "    # save the frequency df\n",
    "    frequencyFeatureDf.to_pickle(os.path.join(fileDir,'frequencyFeaturesDf_{}.pkl'.format(label)))\n",
    "    \n",
    "    # save the channel name list\n",
    "    saveFeatureListToFile(featureList=channelNameList,\n",
    "                          filepath=os.path.join(fileDir, \"features_channel_names.txt\"))\n",
    "    \n",
    "    # save frequency features\n",
    "    saveFeatureListToFile(featureList=list(frequencyFeatureDf.columns),\n",
    "                          filepath=os.path.join(fileDir, \"features_frequency_df.txt\"))\n",
    "\n",
    "def processRawDatasetToPickleFiles(datasetDirPath : str, device : str, awakeFileName : str,\n",
    "                                   fatigueFileName : str, normalFileName : str, unlabeledFileName : str):\n",
    "    '''\n",
    "    @param str datasetDirPath: Path where the directory of the dataset is\n",
    "    @param str device: name of the device, to load the correct yaml file for processing\n",
    "    \n",
    "    Depending on the dataset there might be awake, normal, fatigue or unlabeled data. \n",
    "    @param awakeFileName: filename of the awake data or None then it will be ignored\n",
    "    @param fatigueFileName: filename of the fatigue data or None then it will be ignored\n",
    "    @param normalFileName: filename of the normal data or None then it will be ignored\n",
    "    @param unlabeledFileName: filename of the unlabeled data or None then it will be ignored\n",
    "    '''\n",
    "    \n",
    "    if not os.path.isdir(datasetDirPath):\n",
    "        raise Exception(\"The given dir path '{}' does not exist!\".format(datasetDirPath))\n",
    "        \n",
    "    # Load the yaml config file for the processing\n",
    "    yamlConfig = loadConfigFile(device)\n",
    "    \n",
    "    for root, dirs, files in os.walk(datasetDirPath):\n",
    "        for subjectDir in dirs:\n",
    "            print(\"#############################################\")\n",
    "            print(\"Process Subject {} Data...\".format(subjectDir))\n",
    "            print(\"---------------------------------------------\")\n",
    "            \n",
    "            if awakeFileName is not None: \n",
    "                safeAndProcessRawFileWithPipeline(rawFilePath=os.path.join(root, subjectDir, awakeFilename),\n",
    "                                                  fileDir=os.path.join(root, subjectDir),\n",
    "                                                  label = \"awake\",\n",
    "                                                  yamlConfig=yamlConfig)\n",
    "                \n",
    "            if fatigueFileName is not None: \n",
    "                safeAndProcessRawFileWithPipeline(rawFilePath=os.path.join(root, subjectDir, fatigueFileName),\n",
    "                                                  fileDir=os.path.join(root, subjectDir),\n",
    "                                                  label = \"fatigue\",\n",
    "                                                  yamlConfig=yamlConfig)\n",
    "                \n",
    "            if normalFileName is not None: \n",
    "                safeAndProcessRawFileWithPipeline(rawFilePath=os.path.join(root, subjectDir, normalFileName),\n",
    "                                                  fileDir=os.path.join(root, subjectDir),\n",
    "                                                  label = \"normal\",\n",
    "                                                  yamlConfig=yamlConfig)\n",
    "                \n",
    "            if unlabeledFileName is not None: \n",
    "                safeAndProcessRawFileWithPipeline(rawFilePath=os.path.join(root, subjectDir, normalFileName),\n",
    "                                                  fileDir=os.path.join(root, subjectDir),\n",
    "                                                  label = \"unlabeled\",\n",
    "                                                  yamlConfig=yamlConfig)\n",
    "    \n",
    "    print(\"#######################################\")\n",
    "    print(\"Done processing and saving a complete Dataset!\")\n",
    "\n",
    "def loadPickeldData(dataDir : str, label : str):\n",
    "    ''' Load the epochseries and frequency feature df\n",
    "    \n",
    "    @param str dataDir: Directory where the data is\n",
    "    @param str label: decide which \n",
    "    '''\n",
    "    try:\n",
    "        epochSeries = pd.read_pickle(os.path.join(dataDir,'epochSeries_{}.pkl'.format(label)))\n",
    "    except Exception as e:\n",
    "        #print (e)\n",
    "        epochSeries = None\n",
    "        \n",
    "    try:\n",
    "        frequencyFeatureDf = pd.read_pickle(os.path.join(dataDir,'frequencyFeaturesDf_{}.pkl'.format(label)))\n",
    "    except Exception as e:\n",
    "        #print (e)\n",
    "        frequencyFeatureDf = None\n",
    "\n",
    "    return epochSeries, frequencyFeatureDf\n",
    "\n",
    "def loadPickeldDataset(datasetDirPath : str) -> Dict:\n",
    "    ''' This functions loads a complete dataset into a dict\n",
    "    \n",
    "    Each Subject contains a dict with 'awake', 'normal', 'fatigue' and 'unlabeled' entry.\n",
    "    Each entry contain the epochSeries and frequencyFeatureDf\n",
    "    '''\n",
    "    \n",
    "    if not os.path.isdir(datasetDirPath):\n",
    "        raise Exception(\"The given dir path '{}' does not exist!\".format(datasetDirPath))\n",
    "    \n",
    "    datasetDict = {}\n",
    "    \n",
    "    for root, dirs, files in os.walk(datasetDirPath):\n",
    "        for subjectDir in dirs:\n",
    "            print(\"Load Subject {} Data...\".format(subjectDir))\n",
    "            \n",
    "            epochSeries_awake, frequencyFeatureDf_awake = loadPickeldData(dataDir = os.path.join(datasetDirPath, subjectDir),\n",
    "                                                                          label=\"awake\")\n",
    "            \n",
    "            epochSeries_normal, frequencyFeatureDf_normal = loadPickeldData(dataDir = os.path.join(datasetDirPath, subjectDir),\n",
    "                                                                          label=\"normal\")\n",
    "            \n",
    "            epochSeries_fatigue, frequencyFeatureDf_fatigue = loadPickeldData(dataDir = os.path.join(datasetDirPath, subjectDir),\n",
    "                                                                          label=\"fatigue\")\n",
    "            \n",
    "            epochSeries_unlabeled, frequencyFeatureDf_unlabeled = loadPickeldData(dataDir = os.path.join(datasetDirPath, subjectDir),\n",
    "                                                                          label=\"unlabeled\")\n",
    "            \n",
    "            datasetDict[subjectDir] = {\"awake\" : (epochSeries_awake, frequencyFeatureDf_awake),\n",
    "                                       \"normal\" : (epochSeries_normal, frequencyFeatureDf_normal),\n",
    "                                       \"fatigue\" : (epochSeries_fatigue, frequencyFeatureDf_fatigue),\n",
    "                                       \"unlabeled\" : (epochSeries_unlabeled, frequencyFeatureDf_unlabeled)}\n",
    "    return datasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the config file for neuroscan\n",
      "#############################################\n",
      "Process Subject 1 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\1\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reiss\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\signal\\spectral.py:1966: UserWarning: nperseg = 1024 is greater than input length  = 512, using nperseg = 512\n",
      "  .format(nperseg, input_length))\n",
      "C:\\Users\\reiss\\Anaconda3\\envs\\ml\\lib\\site-packages\\yasa\\spectral.py:237: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bp /= total_power\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bandpower, lower & upper envelope dictionary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Masterthesis\\thesis_eeg\\code\\Transformer_Feature_Extraction.py:184: RuntimeWarning: invalid value encountered in sign\n",
      "  if (np.sign(aTimeSeries[k]-aTimeSeries[k-1])==1) and (np.sign(aTimeSeries[k]-aTimeSeries[k+1])==1) and ((k-lastPeak)>rejectCloserThan):\n",
      "D:\\Masterthesis\\thesis_eeg\\code\\Transformer_Feature_Extraction.py:190: RuntimeWarning: invalid value encountered in sign\n",
      "  if (np.sign(aTimeSeries[k]-aTimeSeries[k-1])==-1) and ((np.sign(aTimeSeries[k]-aTimeSeries[k+1]))==-1) and ((k-lastTrough)>rejectCloserThan):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\1\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\1\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\1\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\1\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\1\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 10 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\10\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\10\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\10\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\10\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\10\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\10\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 11 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\11\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\11\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\11\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\11\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\11\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\11\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 12 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\12\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\12\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\12\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\12\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\12\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\12\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 2 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\2\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\2\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\2\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\2\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\2\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\2\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 3 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\3\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\3\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\3\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\3\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\3\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\3\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 4 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\4\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\4\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\4\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\4\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\4\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\4\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 5 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\5\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\5\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\5\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\5\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\5\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\5\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 6 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\6\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\6\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\6\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\6\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\6\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\6\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 7 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\7\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\7\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\7\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\7\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\7\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\7\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 8 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\8\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\8\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\8\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\8\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\8\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\8\\features_frequency_df.txt'\n",
      "#############################################\n",
      "Process Subject 9 Data...\n",
      "---------------------------------------------\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\9\\Fatigue_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\9\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\9\\features_frequency_df.txt'\n",
      "Starting to process D:/Masterthesis/EEG_Data/eeg_data_online\\9\\Normal_state_256hz.csv...\n",
      "Creating sliding windows...\n",
      "Converting 3d Numpy Array to a series of Df's\n",
      "Normalizing data...\n",
      "Deleting Nan's...\n",
      "Frequenccy Bands: [(0.5, 4, 'Delta'), (4, 8, 'Theta'), (8, 12, 'Alpha'), (12, 30, 'Beta'), (30, 50, 'Gamma')]\n",
      "Creating bandpower, lower & upper envelope dictionary...\n",
      "Creating statistics bandpower dict...\n",
      "Creating a nice feature dataframe...\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\9\\features_channel_names.txt'\n",
      "Saving a feature list to: 'D:/Masterthesis/EEG_Data/eeg_data_online\\9\\features_frequency_df.txt'\n",
      "#######################################\n",
      "Done processing and saving a complete Dataset!\n"
     ]
    }
   ],
   "source": [
    "from consts import DEVICES_NEUROSCAN\n",
    "\n",
    "PROCESS_DATA = False\n",
    "\n",
    "if PROCESS_DATA:\n",
    "    # Process the online EEG Data\n",
    "    processRawDatasetToPickleFiles(datasetDirPath = \"D:/Masterthesis/EEG_Data/eeg_data_online\",\n",
    "                              device = DEVICES_NEUROSCAN,\n",
    "                              awakeFileName = None,\n",
    "                              fatigueFileName = \"Fatigue_state_256hz.csv\",\n",
    "                              normalFileName = \"Normal_state_256hz.csv\",\n",
    "                              unlabeledFileName = None)\n",
    "else:\n",
    "    print (\"Already processed the EEG Online Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Subject 1 Data...\n",
      "Load Subject 10 Data...\n",
      "Load Subject 11 Data...\n",
      "Load Subject 12 Data...\n",
      "Load Subject 2 Data...\n",
      "Load Subject 3 Data...\n",
      "Load Subject 4 Data...\n",
      "Load Subject 5 Data...\n",
      "Load Subject 6 Data...\n",
      "Load Subject 7 Data...\n",
      "Load Subject 8 Data...\n",
      "Load Subject 9 Data...\n"
     ]
    }
   ],
   "source": [
    "eegDataset = loadPickeldDataset(datasetDirPath= \"D:/Masterthesis/EEG_Data/eeg_data_online\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_27</th>\n",
       "      <th>channel_33</th>\n",
       "      <th>channel_36</th>\n",
       "      <th>channel_37</th>\n",
       "      <th>channel_38</th>\n",
       "      <th>channel_39</th>\n",
       "      <th>channel_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.639592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     channel_2  channel_27  channel_33  channel_36  channel_37  channel_38  \\\n",
       "0          NaN         NaN         NaN    0.533807         NaN         NaN   \n",
       "1          NaN         NaN         NaN    0.625042         NaN         NaN   \n",
       "2          NaN         NaN         NaN    0.503881         NaN         NaN   \n",
       "3          NaN         NaN         NaN    0.496285         NaN         NaN   \n",
       "4          NaN         NaN         NaN    0.496285         NaN         NaN   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "507        NaN         NaN         NaN    0.620425         NaN         NaN   \n",
       "508        NaN         NaN         NaN    0.639592         NaN         NaN   \n",
       "509        NaN         NaN         NaN    0.668937         NaN         NaN   \n",
       "510        NaN         NaN         NaN    0.679682         NaN         NaN   \n",
       "511        NaN         NaN         NaN    0.660851         NaN         NaN   \n",
       "\n",
       "     channel_39  channel_40  \n",
       "0           NaN         NaN  \n",
       "1           NaN         NaN  \n",
       "2           NaN         NaN  \n",
       "3           NaN         NaN  \n",
       "4           NaN         NaN  \n",
       "..          ...         ...  \n",
       "507         NaN         NaN  \n",
       "508         NaN         NaN  \n",
       "509         NaN         NaN  \n",
       "510         NaN         NaN  \n",
       "511         NaN         NaN  \n",
       "\n",
       "[512 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_4</th>\n",
       "      <th>channel_5</th>\n",
       "      <th>channel_6</th>\n",
       "      <th>channel_7</th>\n",
       "      <th>channel_8</th>\n",
       "      <th>channel_9</th>\n",
       "      <th>channel_10</th>\n",
       "      <th>...</th>\n",
       "      <th>channel_31</th>\n",
       "      <th>channel_32</th>\n",
       "      <th>channel_33</th>\n",
       "      <th>channel_34</th>\n",
       "      <th>channel_35</th>\n",
       "      <th>channel_36</th>\n",
       "      <th>channel_37</th>\n",
       "      <th>channel_38</th>\n",
       "      <th>channel_39</th>\n",
       "      <th>channel_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     channel_1  channel_2  channel_3  channel_4  channel_5  channel_6  \\\n",
       "0          0.0        0.0        0.0   0.770674        0.0        0.0   \n",
       "1          0.0        0.0        0.0   0.000000        0.0        0.0   \n",
       "2          0.0        0.0        0.0   0.000000        0.0        0.0   \n",
       "3          0.0        0.0        0.0   0.000000        0.0        0.0   \n",
       "4          0.0        0.0        0.0   0.000000        0.0        0.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "507        0.0        0.0        0.0   0.094512        0.0        0.0   \n",
       "508        0.0        0.0        0.0   0.094147        0.0        0.0   \n",
       "509        0.0        0.0        0.0   0.078884        0.0        0.0   \n",
       "510        0.0        0.0        0.0   0.061193        0.0        0.0   \n",
       "511        0.0        0.0        0.0   0.052592        0.0        0.0   \n",
       "\n",
       "     channel_7  channel_8  channel_9  channel_10  ...  channel_31  channel_32  \\\n",
       "0          0.0        0.0        0.0    0.922101  ...         0.0    0.397388   \n",
       "1          0.0        0.0        0.0    0.000000  ...         0.0    0.000000   \n",
       "2          0.0        0.0        0.0    0.000000  ...         0.0    0.000000   \n",
       "3          0.0        0.0        0.0    0.000000  ...         0.0    0.000000   \n",
       "4          0.0        0.0        0.0    0.000000  ...         0.0    0.000000   \n",
       "..         ...        ...        ...         ...  ...         ...         ...   \n",
       "507        0.0        0.0        0.0    0.000000  ...         0.0    0.000000   \n",
       "508        0.0        0.0        0.0    0.000000  ...         0.0    0.000000   \n",
       "509        0.0        0.0        0.0    0.000000  ...         0.0    0.000000   \n",
       "510        0.0        0.0        0.0    0.000000  ...         0.0    0.000000   \n",
       "511        0.0        0.0        0.0    0.000000  ...         0.0    0.000000   \n",
       "\n",
       "     channel_33  channel_34  channel_35  channel_36  channel_37  channel_38  \\\n",
       "0           0.0    0.930844         0.0    0.533807         0.0         0.0   \n",
       "1           0.0    0.000000         0.0    0.625042         0.0         0.0   \n",
       "2           0.0    0.000000         0.0    0.503881         0.0         0.0   \n",
       "3           0.0    0.000000         0.0    0.000000         0.0         0.0   \n",
       "4           0.0    0.000000         0.0    0.000000         0.0         0.0   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "507         0.0    0.000000         0.0    0.620425         0.0         0.0   \n",
       "508         0.0    0.000000         0.0    0.639592         0.0         0.0   \n",
       "509         0.0    0.000000         0.0    0.668937         0.0         0.0   \n",
       "510         0.0    0.000000         0.0    0.679682         0.0         0.0   \n",
       "511         0.0    0.000000         0.0    0.660851         0.0         0.0   \n",
       "\n",
       "     channel_39  channel_40  \n",
       "0           0.0         0.0  \n",
       "1           0.0         0.0  \n",
       "2           0.0         0.0  \n",
       "3           0.0         0.0  \n",
       "4           0.0         0.0  \n",
       "..          ...         ...  \n",
       "507         0.0         0.0  \n",
       "508         0.0         0.0  \n",
       "509         0.0         0.0  \n",
       "510         0.0         0.0  \n",
       "511         0.0         0.0  \n",
       "\n",
       "[512 rows x 40 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegDataset['2']['normal'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSeries = [test]\n",
    "dataSeries = pd.Series(dataSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = convertFreatueDfToXy(eegDataset['2']['normal'][1], target=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertFeatureDfToXy(featureDf : pd.DataFrame, target : int) -> (np.ndarray, np.ndarray):\n",
    "    samples = []\n",
    "    targetArray = []\n",
    "    \n",
    "    for index, row in featureDf.iterrows():\n",
    "        timesteps = []\n",
    "        features = row.to_numpy() # features\n",
    "        timesteps.append(features)\n",
    "        samples.append(timesteps)\n",
    "        \n",
    "        targetArray.append(target)\n",
    "    \n",
    "    X = np.array(samples)\n",
    "    y = np.array(targetArray)\n",
    "    \n",
    "    return X, y \n",
    "    \n",
    "\n",
    "def createXyFromDataSeries(dataSeries : pd.Series, target : int) -> (np.ndarray, np.ndarray):\n",
    "    ''' Create X and y for machine learning\n",
    "    \n",
    "    @param pd.Series dataSeries: Should be a series of dataframes\n",
    "    \n",
    "    X should look like this [samples, timesteps, features]\n",
    "        samples: The epoch\n",
    "        timesteps: E.g. if the epoch contains 200 values then the timestep should contain 200 values\n",
    "        features: The actual value\n",
    "    \n",
    "    y should look tlike this [classIds] \n",
    "        classIds: The label for the sample of the X Data\n",
    "    '''\n",
    "    \n",
    "    samples = []\n",
    "    targetArray = []\n",
    "    \n",
    "    if dataSeries is None:\n",
    "        raise TypeError(\"Data Series is None!\")\n",
    "    \n",
    "    if type(dataSeries) != pd.Series:\n",
    "        raise Exception(\"The given dataSeries is not a pd.Series! It is {}\".format(type(dataSeries)))\n",
    "    \n",
    "    # loop through the data Series\n",
    "    for df in dataSeries:\n",
    "        \n",
    "        if type(df) != pd.DataFrame: # check the type\n",
    "            raise Exception(\"The dataseries contains a {} object - The series should dataframes only!\".format(type(df)))\n",
    "            \n",
    "        timesteps = []\n",
    "            \n",
    "        for index, row in df.iterrows():\n",
    "            features = row.to_numpy() # features\n",
    "            timesteps.append(features)\n",
    "        \n",
    "        samples.append(timesteps)\n",
    "        targetArray.append(target)\n",
    "    \n",
    "    \n",
    "    X = np.array(samples)\n",
    "    y = np.array(targetArray)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def createMachineLearningDataset(eegDataset, targetLabelDict) -> (np.array, np.array):\n",
    "    \n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    for subject in eegDataset:\n",
    "        for target in targetLabelDict:\n",
    "            \n",
    "            try:\n",
    "                print(\"Processing Subject {} - Target: {} ...\".format(subject, target))\n",
    "                eegDataset[subject][target][0]\n",
    "                tempX, tempy = createXyFromDataSeries(dataSeries = eegDataset[subject][target][0],\n",
    "                                       target = targetLabelDict[target])\n",
    "\n",
    "                if X is None:\n",
    "                    X = tempX\n",
    "                else:\n",
    "                    X = np.concatenate((X, tempX))\n",
    "\n",
    "                if y is None:\n",
    "                    y = tempy\n",
    "                else:\n",
    "                    y = np.concatenate((y, tempy))\n",
    "            \n",
    "            except TypeError:\n",
    "                print(\"Skipping Target: {}\".format(target))\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return X,y\n",
    "\n",
    "def saveDictToFile(myDict, filepath : str):\n",
    "    print(\"Saving dict to {}\".format(filepath))\n",
    "    f = open(filepath, \"w\")\n",
    "    for key, value in myDict.items():\n",
    "        line = \"{v} {k}\\n\".format(v=value, k=key.upper())\n",
    "        f.write(str(line))\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "def createAndSafeMlDataset(eegDataset : Dict[str, Dict[str ,Tuple[pd.Series, pd.DataFrame]]], targetLabelDict : Dict,\n",
    "                           featureList : List[str], dirPath : str) -> (np.array, np.array):\n",
    "    \n",
    "    if not os.path.isdir(dirPath):\n",
    "        raise Exception(\"The given directory path is not valid! Given path: {}\".format(dirPath))\n",
    "    \n",
    "    print(\"Creating Machine Learning Dataset!\")\n",
    "    X, y = createMachineLearningDataset(eegDataset, targetLabelDict)\n",
    "    \n",
    "    print(\"\\nSaving Machine Learning Dataset into this directory: {}\".format(dirPath))\n",
    "    np.save(os.path.join(dirPath, \"data_X.npy\"), X)\n",
    "    np.save(os.path.join(dirPath, \"data_y.npy\"), y)\n",
    "    \n",
    "    # Save feature list\n",
    "    \n",
    "    # Save target labels\n",
    "    saveDictToFile(targetLabelDict, filepath=os.path.join(dirPath,'target_labels.txt'))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "#createDatasetXy(dataSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Subject 1 - Target: normal ...\n",
      "Processing Subject 1 - Target: fatigue ...\n",
      "Processing Subject 1 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 1 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 10 - Target: normal ...\n",
      "Processing Subject 10 - Target: fatigue ...\n",
      "Processing Subject 10 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 10 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 11 - Target: normal ...\n",
      "Processing Subject 11 - Target: fatigue ...\n",
      "Processing Subject 11 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 11 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 12 - Target: normal ...\n",
      "Processing Subject 12 - Target: fatigue ...\n",
      "Processing Subject 12 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 12 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 2 - Target: normal ...\n",
      "Processing Subject 2 - Target: fatigue ...\n",
      "Processing Subject 2 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 2 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 3 - Target: normal ...\n",
      "Processing Subject 3 - Target: fatigue ...\n",
      "Processing Subject 3 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 3 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 4 - Target: normal ...\n",
      "Processing Subject 4 - Target: fatigue ...\n",
      "Processing Subject 4 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 4 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 5 - Target: normal ...\n",
      "Processing Subject 5 - Target: fatigue ...\n",
      "Processing Subject 5 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 5 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 6 - Target: normal ...\n",
      "Processing Subject 6 - Target: fatigue ...\n",
      "Processing Subject 6 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 6 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 7 - Target: normal ...\n",
      "Processing Subject 7 - Target: fatigue ...\n",
      "Processing Subject 7 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 7 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 8 - Target: normal ...\n",
      "Processing Subject 8 - Target: fatigue ...\n",
      "Processing Subject 8 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 8 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Processing Subject 9 - Target: normal ...\n",
      "Processing Subject 9 - Target: fatigue ...\n",
      "Processing Subject 9 - Target: awake ...\n",
      "Skipping Target: awake\n",
      "Processing Subject 9 - Target: unlabeled ...\n",
      "Skipping Target: unlabeled\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "targetLabelDict = {\"normal\" : 0,\n",
    "              \"fatigue\" : 1,\n",
    "              \"awake\" : 2,\n",
    "              \"unlabeled\" : 3}\n",
    "\n",
    "X, y = createMachineLearningDataset(eegDataset, targetLabelDict)\n",
    "\n",
    "# Todo epoch series UND frequency df X und y erstellen!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dict to D:/Masterthesis/EEG_Data/eeg_data_online/target_labels.txt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eegDataset['1']['normal'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eegDataset['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('D:/Masterthesis/EEG_Data/eeg_data_online/data_X.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('D:/Masterthesis/EEG_Data/eeg_data_online/data_y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataSeries = eegDataset['2']['normal'][0]\n",
    "#dataSeries = pd.Series(dataSeries)\n",
    "#X, y = createXyFromDataSeries(dataSeries, target=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 512, 40)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-9863f0bfe964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcompleteX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompleteX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "np.concatenate((completeX, X)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 512, 40)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeX.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
