{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to evalute each Model in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Masterthesis\\thesis_eeg\\code\n",
      "Saving images to: D:\\Dropbox\\Apps\\Overleaf\\Masterthesis_Paper\\images\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import json\n",
    "import statistics\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# to enable local imports\n",
    "module_path = os.path.abspath('../code')\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "    \n",
    "from pathlib import Path\n",
    "try:\n",
    "    try:\n",
    "        json_path = (Path(os.getenv('LOCALAPPDATA'))/'Dropbox'/'info.json').resolve()\n",
    "    except FileNotFoundError:\n",
    "        json_path = (Path(os.getenv('APPDATA'))/'Dropbox'/'info.json').resolve()\n",
    "\n",
    "    with open(str(json_path)) as f:\n",
    "        j = json.load(f)\n",
    "\n",
    "    personal_dbox_path = Path(j['personal']['path'])\n",
    "    # Save the images directly into the dropbox where the overleaf document is stored\n",
    "    IMAGES_PATH = os.path.join(str(personal_dbox_path), 'Apps', 'Overleaf', 'Masterthesis_Paper', 'images')\n",
    "\n",
    "except Exception as e:\n",
    "    IMAGES_PATH = \"../images\"\n",
    "    print(e)\n",
    "    \n",
    "print(\"Saving images to: {}\".format(IMAGES_PATH))\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution, bbox_inches='tight')\n",
    "\n",
    "from machine_learning_load_data import loadOnlineEEGdata\n",
    "from utils import loadTargetLabelsTxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Online EEG Data from ../../EEG_Data/eeg_data_online ...\n",
      "Data does not get splitted into train and test!\n",
      "EEG Data Shape:\n",
      "(7178, 512, 40) (7178,)\n",
      "Freq Data Shape:\n",
      "(1440, 1, 1200) (1440,)\n",
      "Entropy Data Shape:\n",
      "(7178, 1, 200) (7178,)\n",
      "Loading Online EEG Data from ../../EEG_Data/muse_data ...\n",
      "Data does not get splitted into train and test!\n",
      "EEG Data Shape:\n",
      "(7705, 512, 4) (7705,)\n",
      "Freq Data Shape:\n",
      "(1549, 1, 120) (1549,)\n",
      "Entropy Data Shape:\n",
      "(7705, 1, 20) (7705,)\n"
     ]
    }
   ],
   "source": [
    "# Load some online EEG Data\n",
    "\n",
    "##################\n",
    "# online eeg data\n",
    "##################\n",
    "eegData, freqData, entropyData = loadOnlineEEGdata(dirPath='../../EEG_Data/eeg_data_online', splitData=False)\n",
    "\n",
    "X_eeg, y_eeg, = eegData\n",
    "X_freq, y_freq = freqData\n",
    "X_entropy, y_entropy = entropyData\n",
    "\n",
    "# reshape\n",
    "X_freq = X_freq.reshape(X_freq.shape[0], X_freq.shape[2])\n",
    "X_entropy = X_entropy.reshape(X_entropy.shape[0], X_entropy.shape[2])\n",
    "\n",
    "targetLabelsDict = loadTargetLabelsTxt(filePath='../../EEG_Data/eeg_data_online/target_labels.txt')\n",
    "targetNames = ['Fatigue ({})'.format(targetLabelsDict['FATIGUE']),\n",
    "               'Normal ({})'.format(targetLabelsDict['NORMAL'])]\n",
    "\n",
    "\n",
    "##################\n",
    "# experiment data\n",
    "##################\n",
    "eegData_exp, freqData_exp, entropyData_exp = loadOnlineEEGdata(dirPath='../../EEG_Data/muse_data', splitData=False)\n",
    "\n",
    "X_eeg_exp, y_eeg_expp = eegData_exp\n",
    "X_freq_exp, y_freq_exp = freqData_exp\n",
    "X_entropy_exp, y_entropy_exp = entropyData_exp\n",
    "\n",
    "# reshape\n",
    "X_freq_exp = X_freq_exp.reshape(X_freq_exp.shape[0], X_freq_exp.shape[2])\n",
    "X_entropy_exp = X_entropy_exp.reshape(X_entropy_exp.shape[0], X_entropy_exp.shape[2])\n",
    "\n",
    "targetLabelsDict_exp = loadTargetLabelsTxt(filePath='../../EEG_Data/muse_data/target_labels.txt')\n",
    "targetNames_exp = ['AWAKE ({})'.format(targetLabelsDict_exp['AWAKE']),\n",
    "               'FATIGUE ({})'.format(targetLabelsDict_exp['FATIGUE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7178, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_entropy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_entropy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to evalute a Model (maybe move into a .py file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "f1_scorer = make_scorer(f1_score) \n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
    "    plt.grid(True)   \n",
    "\n",
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.title(\"Precision versus recall\")\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.grid(True)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    \n",
    "    plt.title(\"Precision versus recall - Threshold Plot\")\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.legend(loc=\"center right\", fontsize=16)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.grid(True)      \n",
    "\n",
    "\n",
    "# Create a model\n",
    "def evaluateModel(model, X, y, kfoldTimes=8, n_jobs=-1, scoring_acc=False, experiment_data=False,\n",
    "                  confusion_matrix_title=\"Confusion Matrix\"):\n",
    "    '''\n",
    "    Function to evalute a model. It evalutes the following metrics:\n",
    "        - Cross Validation: prints each fold; Calculates thea mean and std. dev. and plots/save it.\n",
    "        - Calculate recall, precision and F1 score and plots/save it.\n",
    "        - Calcualte the confusion matrix with the test data and plots/saves it.\n",
    "    \n",
    "    @params:\n",
    "    skLearn 'model': A model from the sklearn package, e.g. from ensemble or a svm\n",
    "    'X': \n",
    "    'y':\n",
    "    'X_test':\n",
    "    'y_test':\n",
    "    int 'kFoldTimes': Number of folds during the cross validation\n",
    "    int 'n_jobs': If -1 then we use all cores. If not set the numbers of cores. None -> 1 Core\n",
    "    Boolean 'scoring_acc': If true we use the accuarcy measurement for the cross validation. If false we use the F1 Scorer.\n",
    "    Boolean 'experiemnt_data': Experiment_data is only used because the targets are a little different\n",
    "    String 'confusion_matrix_title': A title for the confusion matrix. Will be saved with this name as well. \n",
    "    '''\n",
    "    print(\"Model: {}\".format(model))\n",
    "    \n",
    "    # generate cross val score\n",
    "    print(\"Calculating cross val scores...\")\n",
    "    \n",
    "    if scoring_acc:\n",
    "        print(\"X shape: {} --- y shape: {}\".format(X.shape, y.shape))\n",
    "        accuaries = cross_val_score(model, X, y, cv=kfoldTimes, scoring='accuracy', n_jobs=n_jobs)\n",
    "    else:\n",
    "        accuaries = cross_val_score(model, X, y, cv=kfoldTimes, scoring=f1_scorer, n_jobs=n_jobs)\n",
    "    print(\"Cross val scores (Accuracies):\")\n",
    "     \n",
    "    for i in range(0, len(accuaries)):\n",
    "        print(\" Fold {fold}: {acc}\".format(fold=i+1, acc=accuaries[i]))\n",
    "    \n",
    "    \n",
    "    print(\"------------------\")\n",
    "    \n",
    "    mean_acc = statistics.mean(accuaries)\n",
    "    std_dev_acc = statistics.stdev(accuaries)\n",
    "    print(\"Mean: {}\".format(mean_acc))\n",
    "    print(\"Std. Dev.: {}\".format(std_dev_acc))\n",
    "          \n",
    "    \n",
    "    # make predictions with the model\n",
    "    print(\"\\nCaclulating cross val predictions...\")\n",
    "    y_pred = cross_val_predict(model, X, y, cv=kfoldTimes, n_jobs=n_jobs)\n",
    "\n",
    "\n",
    "    my_confusionMatrix = confusion_matrix(y, y_pred)\n",
    "    print(\"\"\"\\nConfusion Matrix\\n------------------------\n",
    "    True Negative:   {tn} - False Positive: {fp}\n",
    "    False Negatives: {fn} - True positive:  {tp}\"\"\".format(tn=my_confusionMatrix[0][0],\n",
    "                                                           fp=my_confusionMatrix[0][1],\n",
    "                                                           fn=my_confusionMatrix[1][0],\n",
    "                                                           tp=my_confusionMatrix[1][1]))\n",
    "    \n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1_score_val = f1_score(y, y_pred)\n",
    "    print(\"Precision: {} \".format(precision))\n",
    "    print(\"Recall:    {}\".format(recall))\n",
    "    print(\"F1 Score:  {}\".format(f1_score_val))\n",
    "    \n",
    "    \"\"\"\n",
    "    # We need to fit the model, to be able to create the confusion matrix\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    if experiment_data:\n",
    "        labels = targetNames_exp\n",
    "    else:\n",
    "        labels = targetNames\n",
    "    \n",
    "    disp = plot_confusion_matrix(model, X_test, y_test,\n",
    "                                 display_labels=labels,\n",
    "                                 normalize=None, # None => no normalization\n",
    "                                 cmap=plt.cm.Blues)\n",
    "    disp.ax_.set_title(confusion_matrix_title)\n",
    "    \n",
    "    # save confusion matrix\n",
    "    save_fig(confusion_matrix_title)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate and plot the precion-recall tradeoff\n",
    "    model.fit(X, y)\n",
    "    y_score = model.decision_function(X)\n",
    "    average_precision = average_precision_score(y, y_score)\n",
    "    print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "    \n",
    "    disp = plot_precision_recall_curve(model, X, y)\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "    \n",
    "    \n",
    "    # Calculate and plot precision vs. recall - threshold plot\n",
    "    y_scores_dec_func = cross_val_predict(model, X, y, cv=kfoldTimes, method=\"decision_function\", n_jobs=n_jobs)\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y, y_scores_dec_func)\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "    \n",
    "    # Plot precision vs. recall directly against each other\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    \n",
    "    \n",
    "    # Calculate and plot the ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_scores_dec_func)\n",
    "    plt.figure(figsize=(8, 6)) \n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    \n",
    "    \n",
    "    # Compare to another model\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    y_probas_forest = cross_val_predict(forest_clf, X, y, cv=kfoldTimes, method=\"predict_proba\", n_jobs=n_jobs)\n",
    "    \n",
    "    y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n",
    "    fpr_forest, tpr_forest, thresholds_forest = roc_curve(y, y_scores_forest)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"SVM\")\n",
    "    plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"lower right\", fontsize=16)\n",
    "    \"\"\"\n",
    "    \n",
    "    return (mean_acc, std_dev_acc, precision, recall, f1_score_val)\n",
    "    \n",
    "def evaluteModelTypes(modelList, scoring_acc=False):\n",
    "    \n",
    "    statistics_data = {}\n",
    "    \n",
    "    for modelType, model in models:\n",
    "        if modelType == 'entropy':\n",
    "            print(\"\\n######### Entropy - Online EEG Data #########\")\n",
    "            data = evaluateModel(model=model, X=X_entropy, y=y_entropy,\n",
    "                                 scoring_acc=scoring_acc, experiment_data=False,\n",
    "                                 confusion_matrix_title='{model_name}_online_entropy_data'.format(model_name=type(model).__name__))\n",
    "            statistics_data['entropy'] = data\n",
    "\n",
    "        elif modelType == 'frequency':\n",
    "            print(\"\\n######### Frequency - Online EEG Data #########\")\n",
    "            data = evaluateModel(model=model, X=X_freq, y=y_freq,\n",
    "                                 scoring_acc=scoring_acc, experiment_data=False,\n",
    "                                 confusion_matrix_title='{model_name}_online_frequency_data'.format(model_name=type(model).__name__))\n",
    "            statistics_data['frequency'] = data\n",
    "\n",
    "        elif modelType == 'entropy_exp':\n",
    "            print(\"\\n######### Entropy - Experiment Data #########\")\n",
    "            data = evaluateModel(model=model, X=X_entropy_exp, y=y_entropy_exp,\n",
    "                                 scoring_acc=scoring_acc, experiment_data=True,\n",
    "                                 confusion_matrix_title='{model_name}_experiment_entropy_data'.format(model_name=type(model).__name__))\n",
    "            statistics_data['entropy_exp'] = data\n",
    "\n",
    "        elif modelType == 'frequency_exp':\n",
    "            print(\"\\n######### Frequency - Experiment Data #########\")\n",
    "            data = evaluateModel(model=model, X=X_freq_exp, y=y_freq_exp,\n",
    "                                 scoring_acc=scoring_acc, experiment_data=True,\n",
    "                                 confusion_matrix_title='{model_name}_experiment_frequency_data'.format(model_name=type(model).__name__))\n",
    "            statistics_data['frequency_exp'] = data\n",
    "        else:\n",
    "            print(\"Invalid modelType: {}\".format(modelType))\n",
    "            \n",
    "    return statistics_data\n",
    "\n",
    "\n",
    "\n",
    "def plot_accuaries(statistics_data:Dict, title:str):\n",
    "    \n",
    "    # Define labels, positions, bar heights and error bar heights\n",
    "    labels = ['Entropy\\nOnline Data', 'Frequency\\nOnline Data', 'Entropy\\nExperiment Data', 'Frequency\\nExperiment Data']\n",
    "    x_pos = np.arange(len(labels))\n",
    "    CTEs = [statistics_data['entropy'][0], statistics_data['frequency'][0], statistics_data['entropy_exp'][0], statistics_data['frequency_exp'][0]]\n",
    "    error = [statistics_data['entropy'][1], statistics_data['frequency'][1], statistics_data['entropy_exp'][1], statistics_data['frequency_exp'][1]]\n",
    "    \n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    ax.bar(x_pos, CTEs,\n",
    "           yerr=error,\n",
    "           align='center',\n",
    "           alpha=0.5,\n",
    "           ecolor='black',\n",
    "           capsize=10)\n",
    "    ax.set_ylabel('Accuracies')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title(title)\n",
    "    ax.yaxis.grid(True)\n",
    "    \n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "    # Save the figure and show\n",
    "    save_fig(\"{}_acc\".format(title.replace(\" \", \"_\")))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_metrcis(statistics_data:Dict, title:str):\n",
    "    \n",
    "    # Define labels, positions, bar heights and error bar heights\n",
    "    labels = ['Entropy\\nOnline Data', 'Frequency\\nOnline Data', 'Entropy\\nExperiment Data', 'Frequency\\nExperiment Data']\n",
    "    x_pos = np.arange(len(labels))\n",
    "    \n",
    "    precision = [statistics_data['entropy'][2], statistics_data['frequency'][2], statistics_data['entropy_exp'][2], statistics_data['frequency_exp'][2]]\n",
    "    recall = [statistics_data['entropy'][3], statistics_data['frequency'][3], statistics_data['entropy_exp'][3], statistics_data['frequency_exp'][3]]\n",
    "    f1_score_val = [statistics_data['entropy'][4], statistics_data['frequency'][4], statistics_data['entropy_exp'][4], statistics_data['frequency_exp'][4]]\n",
    "    \n",
    "    # create plot\n",
    "    width = 0.2    \n",
    "    fig, ax = plt.subplots(figsize=(12,5))\n",
    "    plt.bar(x_pos, precision, width, label='Precision')\n",
    "    plt.bar(x_pos + width, recall, width, label='Recall')\n",
    "    plt.bar(x_pos + width*2, f1_score_val, width, label='F1 Score')\n",
    "    \n",
    "    \n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_xticks(x_pos + width)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title(title)\n",
    "    ax.yaxis.grid(True)\n",
    "    \n",
    "    \n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "    plt.legend(loc='best')\n",
    "    # Save the figure and show\n",
    "    save_fig(\"{}_metrics\".format(title.replace(\" \", \"_\")))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForestClassifier'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " type(models[0][1]).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Entropy - Online EEG Data #########\n",
      "Model: DecisionTreeClassifier(splitter='random')\n",
      "Calculating cross val scores...\n",
      "X shape: (7178, 200) --- y shape: (1440,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7178, 1440]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8d07a052fb32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frequency_exp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'entropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'random'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mstatisticsData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluteModelTypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplot_accuaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatisticsData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Decision Tree\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplot_metrcis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatisticsData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Decision Tree\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ebadd9b584ea>\u001b[0m in \u001b[0;36mevaluteModelTypes\u001b[1;34m(modelList, scoring_acc)\u001b[0m\n\u001b[0;32m    181\u001b[0m             data = evaluateModel(model=model, X=X_entropy, y=y_entropy,\n\u001b[0;32m    182\u001b[0m                                  \u001b[0mscoring_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                                  confusion_matrix_title='{model_name}_online_entropy_data'.format(model_name=type(model).__name__))\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[0mstatistics_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entropy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ebadd9b584ea>\u001b[0m in \u001b[0;36mevaluateModel\u001b[1;34m(model, X, y, kfoldTimes, n_jobs, scoring_acc, experiment_data, confusion_matrix_title)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscoring_acc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X shape: {} --- y shape: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0maccuaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfoldTimes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0maccuaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfoldTimes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf1_scorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    404\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    407\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \"\"\"\n\u001b[1;32m--> 233\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \"\"\"\n\u001b[0;32m    292\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 257\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7178, 1440]"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('entropy', DecisionTreeClassifier(criterion='gini', splitter='random')))\n",
    "models.append(('frequency', DecisionTreeClassifier(criterion='entropy', splitter='random')))\n",
    "models.append(('entropy_exp', DecisionTreeClassifier(criterion='gini', splitter='random')))\n",
    "models.append(('frequency_exp', DecisionTreeClassifier(criterion='entropy', splitter='random')))\n",
    "\n",
    "statisticsData = evaluteModelTypes(models, scoring_acc=True)\n",
    "plot_accuaries(statisticsData, title=\"Decision Tree\")\n",
    "plot_metrcis(statisticsData, title=\"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Entropy - Online EEG Data #########\n",
      "Model: SVC(degree=5, kernel='poly')\n",
      "Calculating cross val scores...\n",
      "Cross val scores (Accuracies):\n",
      " Fold 1: 0.5207006369426752\n",
      " Fold 2: 0.678343949044586\n",
      " Fold 3: 0.6369426751592356\n",
      " Fold 4: 0.8073248407643312\n",
      " Fold 5: 0.7340764331210191\n",
      " Fold 6: 0.9187898089171974\n",
      " Fold 7: 0.8535031847133758\n",
      " Fold 8: 0.8455414012738853\n",
      "------------------\n",
      "Mean: 0.7494028662420382\n",
      "Std. Dev.: 0.13221338771398994\n",
      "\n",
      "Caclulating cross val predictions...\n",
      "\n",
      "Confusion Matrix\n",
      "------------------------\n",
      "    True Negative:   1541 - False Positive: 852\n",
      "    False Negatives: 407 - True positive:  2224\n",
      "----------------------\n",
      "Precision: 0.7230169050715215 \n",
      "Recall:    0.8453059673128088\n",
      "F1 Score:  0.7793937270019274\n",
      "\n",
      "######### Frequency - Online EEG Data #########\n",
      "Model: SVC(degree=5, kernel='poly')\n",
      "Calculating cross val scores...\n",
      "Cross val scores (Accuracies):\n",
      " Fold 1: 0.3968253968253968\n",
      " Fold 2: 0.4523809523809524\n",
      " Fold 3: 0.5952380952380952\n",
      " Fold 4: 0.5158730158730159\n",
      " Fold 5: 0.5079365079365079\n",
      " Fold 6: 0.8333333333333334\n",
      " Fold 7: 0.5476190476190477\n",
      " Fold 8: 0.6587301587301587\n",
      "------------------\n",
      "Mean: 0.5634920634920635\n",
      "Std. Dev.: 0.13555274097350428\n",
      "\n",
      "Caclulating cross val predictions...\n",
      "\n",
      "Confusion Matrix\n",
      "------------------------\n",
      "    True Negative:   383 - False Positive: 145\n",
      "    False Negatives: 295 - True positive:  185\n",
      "----------------------\n",
      "Precision: 0.5606060606060606 \n",
      "Recall:    0.3854166666666667\n",
      "F1 Score:  0.45679012345679004\n",
      "\n",
      "######### Entropy - Experiment Data #########\n",
      "Model: SVC(degree=5, kernel='poly')\n",
      "Calculating cross val scores...\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('entropy', svm.SVC(kernel='poly', gamma='scale', degree=5)))\n",
    "models.append(('frequency', svm.SVC(kernel='poly', gamma='scale', degree=5)))\n",
    "models.append(('entropy_exp', svm.SVC(kernel='poly', gamma='scale', degree=5)))\n",
    "models.append(('frequency_exp', svm.SVC(kernel='poly', gamma='scale', degree=5)))\n",
    "\n",
    "evaluteModelTypes(models, scoring_acc=True)\n",
    "plot_accuaries(statisticsData, title=\"Support Vector Machine\")\n",
    "plot_metrcis(statisticsData, title=\"Support Vector Machine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Entropy - Online EEG Data #########\n",
      "Model: RandomForestClassifier(criterion='entropy', max_features='log2',\n",
      "                       n_estimators=500)\n",
      "Calculating cross val scores...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a863cfb6641a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frequency_exp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'log2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mevaluteModelTypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-98ee91a00554>\u001b[0m in \u001b[0;36mevaluteModelTypes\u001b[1;34m(modelList, scoring_acc)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n######### Entropy - Online EEG Data #########\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             data = evaluateModel(model=model, X_train=X_train_entropy, y_train=y_train_entropy, X_test=X_test_entropy, y_test=y_test_entropy,\n\u001b[1;32m--> 164\u001b[1;33m                           scoring_acc=scoring_acc, experiment_data=False)\n\u001b[0m\u001b[0;32m    165\u001b[0m             \u001b[0mstatistics_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entropy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-98ee91a00554>\u001b[0m in \u001b[0;36mevaluateModel\u001b[1;34m(model, X_train, y_train, X_test, y_test, kfoldTimes, n_jobs, scoring_acc, experiment_data)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscoring_acc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0maccuaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfoldTimes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0maccuaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfoldTimes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf1_scorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    404\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    407\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 248\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('entropy', RandomForestClassifier(max_features='log2', n_estimators=500, criterion='entropy')))\n",
    "models.append(('frequency', RandomForestClassifier(max_features='log2', n_estimators=1000, criterion='entropy')))\n",
    "models.append(('entropy_exp', RandomForestClassifier(max_features='log2', n_estimators=500, criterion='entropy')))\n",
    "models.append(('frequency_exp', RandomForestClassifier(max_features='log2', n_estimators=1000, criterion='gini')))\n",
    "\n",
    "evaluteModelTypes(models, scoring_acc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbour (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('entropy', KNeighborsClassifier(n_neighbors=5, weights='distance')))\n",
    "models.append(('frequency', KNeighborsClassifier(n_neighbors=5, weights='distance')))\n",
    "models.append(('entropy_exp', KNeighborsClassifier(n_neighbors=5, weights='distance')))\n",
    "models.append(('frequency_exp', KNeighborsClassifier(n_neighbors=5, weights='distance')))\n",
    "\n",
    "evaluteModelTypes(models, scoring_acc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('entropy', GradientBoostingClassifier(learning_rate=0.1, n_estimators=1000, loss='deviance')))\n",
    "models.append(('frequency', GradientBoostingClassifier(learning_rate=0.1, n_estimators=1000, loss='deviance')))\n",
    "models.append(('entropy_exp', GradientBoostingClassifier(learning_rate=0.1, n_estimators=1000, loss='deviance')))\n",
    "models.append(('frequency_exp', GradientBoostingClassifier(learning_rate=0.1, n_estimators=1000, loss='deviance')))\n",
    "\n",
    "evaluteModelTypes(models, scoring_acc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('entropy', AdaBoostClassifier(learning_rate=1.2, n_estimators=1000)))\n",
    "models.append(('frequency', AdaBoostClassifier(learning_rate=1.2, n_estimators=1000)))\n",
    "models.append(('entropy_exp', AdaBoostClassifier(learning_rate=1.2, n_estimators=1000)))\n",
    "models.append(('frequency_exp', AdaBoostClassifier(learning_rate=1.2, n_estimators=1000)))\n",
    "\n",
    "evaluteModelTypes(models, scoring_acc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('entropy', MLPClassifier(shuffle=True, hidden_layer_sizes=(4, 100), solver='adam', activation='tanh', learning_rate='constant', learning_rate_init=0.001, alpha=0.0001))\n",
    "models.append(('frequency', MLPClassifier(shuffle=True, hidden_layer_sizes=(2, 100), solver='adam', activation='relu', learning_rate='constant', learning_rate_init=0.001, alpha=0.0001)))\n",
    "models.append(('entropy_exp', MLPClassifier(shuffle=True, hidden_layer_sizes=(2, 200), solver='adam', activation='relu', learning_rate='constant', learning_rate_init=0.001, alpha=0.0001)))\n",
    "models.append(('frequency_exp', MLPClassifier(shuffle=True, hidden_layer_sizes=(4, 50), solver='adam', activation='tanh', learning_rate='constant', learning_rate_init=0.001, alpha=0.0001)))\n",
    "\n",
    "evaluteModelTypes(models, scoring_acc=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
