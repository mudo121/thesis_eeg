{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classification (with feature importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mudo121/thesis_eeg/blob/master/machine_learning_notebooks/random_forest.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nvidia/masterthesis/thesis_eeg/code\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to enable local imports\n",
    "module_path = os.path.abspath('../code')\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from machine_learning_load_data import loadOnlineEEGdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Online EEG Data from ../../EEG_Data/eeg_data_online ...\n",
      "EEG Data Shape:\n",
      "(5024, 512, 40) (5024,) (2154, 512, 40) (2154,)\n",
      "Freq Data Shape:\n",
      "(1008, 1, 1200) (1008,) (432, 1, 1200) (432,)\n",
      "Entropy Data Shape:\n",
      "(5024, 1, 200) (5024,) (2154, 1, 200) (2154,)\n"
     ]
    }
   ],
   "source": [
    "# Load some online EEG Data\n",
    "eegData, freqData, entropyData = loadOnlineEEGdata(dirPath='../../EEG_Data/eeg_data_online', splitData=True)\n",
    "eegX_train, eegy_train, eegX_test, eegy_test = eegData\n",
    "freqX_train, freqy_train, freqX_test, freqy_test = freqData\n",
    "X_train_entropy, y_train_entropy, X_test_entropy, y_test_entropy = entropyData\n",
    "\n",
    "# reshape\n",
    "freqX_train = freqX_train.reshape(freqX_train.shape[0], freqX_train.shape[2])\n",
    "freqX_test = freqX_test.reshape(freqX_test.shape[0], freqX_test.shape[2])\n",
    "\n",
    "X_train_entropy = X_train_entropy.reshape(X_train_entropy.shape[0], X_train_entropy.shape[2])\n",
    "X_test_entropy = X_test_entropy.reshape(X_test_entropy.shape[0], X_test_entropy.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "f1_scorer = make_scorer(f1_score) \n",
    "\n",
    "# Create a model\n",
    "def evaluateModel(model,X_train, y_train, kfoldTimes=8, n_jobs=None):\n",
    "    \n",
    "    print(\"Model: {}\".format(model))\n",
    "\n",
    "    # generate cross val score\n",
    "    kfoldTimes = kfoldTimes\n",
    "    print(\"Calculating cross val scores...\")\n",
    "    accuaries = cross_val_score(model, X_train, y_train, cv=kfoldTimes, scoring=f1_scorer, n_jobs=n_jobs)\n",
    "    print(\"Cross val scores (Accuracies):\")\n",
    "    for i in range(0, len(accuaries)):\n",
    "        print(\" Fold {fold}: {acc}\".format(fold=i+1, acc=accuaries[i]))\n",
    "\n",
    "    # make predictions with the model\n",
    "    print(\"\\nCaclulating cross val predictions...\")\n",
    "    y_train_pred = cross_val_predict(model, X_train, y_train, cv=kfoldTimes, n_jobs=n_jobs)\n",
    "\n",
    "\n",
    "    svm_confusionMatrix = confusion_matrix(y_train, y_train_pred)\n",
    "    print(\"\"\"\\nConfusion Matrix\\n------------------------\n",
    "    True Negative:   {tn} - False Positive: {fp}\n",
    "    False Negatives: {fn} - True positive:  {tp}\"\"\".format(tn=svm_confusionMatrix[0][0],\n",
    "                                                           fp=svm_confusionMatrix[0][1],\n",
    "                                                           fn=svm_confusionMatrix[1][0],\n",
    "                                                           tp=svm_confusionMatrix[1][1]))\n",
    "\n",
    "    print(\"----------------------\")\n",
    "    print(\"Precision: {} \".format(precision_score(y_train, y_train_pred)))\n",
    "    print(\"Recall:    {}\".format(recall_score(y_train, y_train_pred)))\n",
    "    print(\"F1 Score:  {}\".format(f1_score(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=16, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False)\n",
      "Calculating cross val scores...\n",
      "Cross val scores (Accuracies):\n",
      " Fold 1: 0.10207939508506617\n",
      " Fold 2: 0.5725915875169607\n",
      " Fold 3: 0.4761904761904763\n",
      " Fold 4: 0.71731843575419\n",
      " Fold 5: 0.6969026548672566\n",
      " Fold 6: 0.8240109140518417\n",
      " Fold 7: 0.4659400544959128\n",
      " Fold 8: 0.5524625267665952\n",
      "\n",
      "Caclulating cross val predictions...\n",
      "\n",
      "Confusion Matrix\n",
      "------------------------\n",
      "    True Negative:   1189 - False Positive: 1204\n",
      "    False Negatives: 1028 - True positive:  1603\n",
      "----------------------\n",
      "Precision: 0.571072319201995 \n",
      "Recall:    0.6092740402888636\n",
      "F1 Score:  0.5895549834497977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "evaluateModel(model=RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1),\n",
    "              X_train=X_train_entropy,\n",
    "              y_train=y_train_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a model to test\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Create a parameter grid - here you specifiy which combinations you want to test\n",
    "param_grid = [\n",
    "    {'n_estimators': [500, 1000, 2000],\n",
    "     'min_samples_split' : [2, 4, 8],\n",
    "     'criterion' : ['gini', 'entropy'],\n",
    "     'max_features' : ['auto', 'log2'],\n",
    "    }\n",
    "]\n",
    "\n",
    "kFoldTimes = 8\n",
    "\n",
    "# create a grid search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=kFoldTimes,\n",
    "                            scoring=f1_scorer,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "# fit it with the data\n",
    "result = grid_search.fit(X_train_entropy, y_train_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 2000, 'criterion': 'entropy'}\n",
      "Best Estimator: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=None, max_features='log2',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.6154663116812853 {'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 500, 'criterion': 'gini'}\n",
      "0.6198912904171416 {'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 1000, 'criterion': 'gini'}\n",
      "0.6190303375797785 {'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 2000, 'criterion': 'gini'}\n",
      "0.6162882956763078 {'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 500, 'criterion': 'gini'}\n",
      "0.6192769724556026 {'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 1000, 'criterion': 'gini'}\n",
      "0.6180351814057765 {'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 2000, 'criterion': 'gini'}\n",
      "0.6172798715871002 {'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 500, 'criterion': 'gini'}\n",
      "0.6194194189798939 {'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 1000, 'criterion': 'gini'}\n",
      "0.6184816200513787 {'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 2000, 'criterion': 'gini'}\n",
      "0.6203972845150422 {'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 500, 'criterion': 'gini'}\n",
      "0.6302848717684733 {'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'criterion': 'gini'}\n",
      "0.6266326933791573 {'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 2000, 'criterion': 'gini'}\n",
      "0.6245517798107468 {'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 500, 'criterion': 'gini'}\n",
      "0.6291531349392359 {'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 1000, 'criterion': 'gini'}\n",
      "0.6278249920110922 {'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 2000, 'criterion': 'gini'}\n",
      "0.6244480843416409 {'max_features': 'log2', 'min_samples_split': 8, 'n_estimators': 500, 'criterion': 'gini'}\n",
      "0.6285332369982124 {'max_features': 'log2', 'min_samples_split': 8, 'n_estimators': 1000, 'criterion': 'gini'}\n",
      "0.6274915611077921 {'max_features': 'log2', 'min_samples_split': 8, 'n_estimators': 2000, 'criterion': 'gini'}\n",
      "0.6223512867963339 {'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 500, 'criterion': 'entropy'}\n",
      "0.6206983589972326 {'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 1000, 'criterion': 'entropy'}\n",
      "0.6203115029297435 {'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 2000, 'criterion': 'entropy'}\n",
      "0.6218648899242873 {'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 500, 'criterion': 'entropy'}\n",
      "0.621973767250958 {'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 1000, 'criterion': 'entropy'}\n",
      "0.6190672012702818 {'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 2000, 'criterion': 'entropy'}\n",
      "0.6214551965637674 {'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 500, 'criterion': 'entropy'}\n",
      "0.618632284162566 {'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 1000, 'criterion': 'entropy'}\n",
      "0.6224708758736598 {'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 2000, 'criterion': 'entropy'}\n",
      "0.6260444491752588 {'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 500, 'criterion': 'entropy'}\n",
      "0.6319566944509021 {'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'criterion': 'entropy'}\n",
      "0.626914350753626 {'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 2000, 'criterion': 'entropy'}\n",
      "0.6288597710598991 {'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 500, 'criterion': 'entropy'}\n",
      "0.6307038694385814 {'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 1000, 'criterion': 'entropy'}\n",
      "0.632037041729186 {'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 2000, 'criterion': 'entropy'}\n",
      "0.6253435329924457 {'max_features': 'log2', 'min_samples_split': 8, 'n_estimators': 500, 'criterion': 'entropy'}\n",
      "0.6292688769625809 {'max_features': 'log2', 'min_samples_split': 8, 'n_estimators': 1000, 'criterion': 'entropy'}\n",
      "0.6300428236068772 {'max_features': 'log2', 'min_samples_split': 8, 'n_estimators': 2000, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Params: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Estimator: {}\".format(grid_search.best_estimator_))\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='log2',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=4,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateModel(grid_search.best_estimator_, X_train_entropy, y_train_entropy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
