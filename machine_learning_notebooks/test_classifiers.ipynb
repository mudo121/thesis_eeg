{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to test Classififers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Masterthesis\\thesis_eeg\\code\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "# Import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "f1_scorer = make_scorer(f1_score) \n",
    "\n",
    "# to enable local imports\n",
    "module_path = os.path.abspath('../code')\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from machine_learning_load_data import loadOnlineEEGdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Online EEG Data from ../../EEG_Data/eeg_data_online ...\n",
      "EEG Data Shape:\n",
      "(5024, 512, 40) (5024,) (2154, 512, 40) (2154,)\n",
      "Freq Data Shape:\n",
      "(1008, 1, 1200) (1008,) (432, 1, 1200) (432,)\n",
      "Entropy Data Shape:\n",
      "(5024, 1, 200) (5024,) (2154, 1, 200) (2154,)\n"
     ]
    }
   ],
   "source": [
    "# Load some online EEG Data\n",
    "eegData, freqData, entropyData = loadOnlineEEGdata(dirPath='../../EEG_Data/eeg_data_online', splitData=True)\n",
    "eegX_train, eegy_train, eegX_test, eegy_test = eegData\n",
    "freqX_train, freqy_train, freqX_test, freqy_test = freqData\n",
    "X_train_entropy, y_train_entropy, X_test_entropy, y_test_entropy = entropyData\n",
    "\n",
    "# reshape\n",
    "freqX_train = freqX_train.reshape(freqX_train.shape[0], freqX_train.shape[2])\n",
    "freqX_test = freqX_test.reshape(freqX_test.shape[0], freqX_test.shape[2])\n",
    "\n",
    "X_train_entropy = X_train_entropy.reshape(X_train_entropy.shape[0], X_train_entropy.shape[2])\n",
    "X_test_entropy = X_test_entropy.reshape(X_test_entropy.shape[0], X_test_entropy.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def testModel(model, paramGrid, X, y, n_jobs=-1, scoring=f1_scorer, kFoldTimes=8):\n",
    "    ''' Test the Model with the '''\n",
    "    start_time = time.time()\n",
    "    print(\"Testing Classifier: {}\".format(model.__class__.__name__))\n",
    "    print(\"Scoring: {}\".format(scoring))\n",
    "    print(\"K-fold times: {} --- n-jobs: {}\".format(kFoldTimes, n_jobs))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # create a grid search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kFoldTimes, scoring=scoring, return_train_score=True, n_jobs=n_jobs)\n",
    "\n",
    "    # fit it with the data\n",
    "    result = grid_search.fit(X_train_entropy, y_train_entropy)\n",
    "\n",
    "    print(\"Best Params: {}\".format(grid_search.best_params_))\n",
    "    print(\"Best Estimator: {}\".format(grid_search.best_estimator_))\n",
    "\n",
    "    cvres = grid_search.cv_results_\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        print(mean_score, params)\n",
    "    \n",
    "    print('Minutes taken: ',(time.time() - start_time)/60)\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classifier: DecisionTreeClassifier\n",
      "Scoring: make_scorer(f1_score)\n",
      "K-fold times: 8 - n-jobs: -1\n",
      "\n",
      "\n",
      "Best Params: {'splitter': 'random', 'criterion': 'gini'}\n",
      "Best Estimator: DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='random')\n",
      "0.5705124777656854 {'splitter': 'best', 'criterion': 'gini'}\n",
      "0.6246980931136836 {'splitter': 'random', 'criterion': 'gini'}\n",
      "0.5923053403801248 {'splitter': 'best', 'criterion': 'entropy'}\n",
      "0.5886940216322119 {'splitter': 'random', 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "param_grid = [\n",
    "        {'criterion' : ['gini', 'entropy'],\n",
    "         'splitter' : ['best', 'random'],\n",
    "    }\n",
    "]\n",
    "\n",
    "bestEstimator = testModel(model=model, paramGrid=param_grid, X=X_train_entropy, y=y_train_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suport Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classifier: SVC\n",
      "Scoring: make_scorer(f1_score)\n",
      "K-fold times: 8 - n-jobs: -1\n",
      "\n",
      "\n",
      "Best Params: {'kernel': 'poly', 'gamma': 'scale', 'degree': 5}\n",
      "Best Estimator: SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=5, gamma='scale', kernel='poly',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.6806950784521192 {'kernel': 'poly', 'gamma': 'scale', 'degree': 2}\n",
      "0.6355423926744519 {'kernel': 'rbf', 'gamma': 'scale', 'degree': 2}\n",
      "0.37033703183201777 {'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 2}\n",
      "0.5378505845740114 {'kernel': 'poly', 'gamma': 'auto', 'degree': 2}\n",
      "0.5387078800790277 {'kernel': 'rbf', 'gamma': 'auto', 'degree': 2}\n",
      "0.5569480021449209 {'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 2}\n",
      "0.7307867402396362 {'kernel': 'poly', 'gamma': 'scale', 'degree': 3}\n",
      "0.6355423926744519 {'kernel': 'rbf', 'gamma': 'scale', 'degree': 3}\n",
      "0.37033703183201777 {'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 3}\n",
      "0.528714721477656 {'kernel': 'poly', 'gamma': 'auto', 'degree': 3}\n",
      "0.5387078800790277 {'kernel': 'rbf', 'gamma': 'auto', 'degree': 3}\n",
      "0.5569480021449209 {'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 3}\n",
      "0.7439136642905952 {'kernel': 'poly', 'gamma': 'scale', 'degree': 5}\n",
      "0.6355423926744519 {'kernel': 'rbf', 'gamma': 'scale', 'degree': 5}\n",
      "0.37033703183201777 {'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 5}\n",
      "0.48405891017340164 {'kernel': 'poly', 'gamma': 'auto', 'degree': 5}\n",
      "0.5387078800790277 {'kernel': 'rbf', 'gamma': 'auto', 'degree': 5}\n",
      "0.5569480021449209 {'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 5}\n",
      "0.7195543246123505 {'kernel': 'poly', 'gamma': 'scale', 'degree': 10}\n",
      "0.6355423926744519 {'kernel': 'rbf', 'gamma': 'scale', 'degree': 10}\n",
      "0.37033703183201777 {'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 10}\n",
      "0.648364050267316 {'kernel': 'poly', 'gamma': 'auto', 'degree': 10}\n",
      "0.5387078800790277 {'kernel': 'rbf', 'gamma': 'auto', 'degree': 10}\n",
      "0.5569480021449209 {'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Create a model to test\n",
    "model = svm.SVC()\n",
    "\n",
    "# Create a parameter grid - here you specifiy which combinations you want to test\n",
    "param_grid = [\n",
    "    {'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "     'degree': [2, 3, 5, 10], # only for poly kernel\n",
    "     'gamma': ['scale', 'auto']\n",
    "    }\n",
    "]\n",
    "    \n",
    "bestEstimator = testModel(model=model, paramGrid=param_grid, X=X_train_entropy, y=y_train_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classifier: RandomForestClassifier\n",
      "Scoring: make_scorer(f1_score)\n",
      "K-fold times: 8 --- n-jobs: -1\n",
      "\n",
      "\n",
      "Best Params: {'criterion': 'entropy', 'n_estimators': 1000, 'max_features': 'log2'}\n",
      "Best Estimator: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=None, max_features='log2',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.6193077476867548 {'criterion': 'gini', 'n_estimators': 500, 'max_features': 'auto'}\n",
      "0.6223405106201894 {'criterion': 'gini', 'n_estimators': 1000, 'max_features': 'auto'}\n",
      "0.619015870842172 {'criterion': 'gini', 'n_estimators': 2000, 'max_features': 'auto'}\n",
      "0.6254095218680995 {'criterion': 'gini', 'n_estimators': 500, 'max_features': 'log2'}\n",
      "0.624704514653878 {'criterion': 'gini', 'n_estimators': 1000, 'max_features': 'log2'}\n",
      "0.627327071191129 {'criterion': 'gini', 'n_estimators': 2000, 'max_features': 'log2'}\n",
      "0.6255554146213718 {'criterion': 'entropy', 'n_estimators': 500, 'max_features': 'auto'}\n",
      "0.6192492247649702 {'criterion': 'entropy', 'n_estimators': 1000, 'max_features': 'auto'}\n",
      "0.622366326822135 {'criterion': 'entropy', 'n_estimators': 2000, 'max_features': 'auto'}\n",
      "0.6281663450362704 {'criterion': 'entropy', 'n_estimators': 500, 'max_features': 'log2'}\n",
      "0.6322442059158226 {'criterion': 'entropy', 'n_estimators': 1000, 'max_features': 'log2'}\n",
      "0.6320308665075973 {'criterion': 'entropy', 'n_estimators': 2000, 'max_features': 'log2'}\n",
      "Minutes taken:  50.40317797263463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a model to test\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Create a parameter grid - here you specifiy which combinations you want to test\n",
    "param_grid = [\n",
    "    {'n_estimators': [500, 1000, 2000], # 1000 seems good\n",
    "     #'min_samples_split' : [2, 4, 8],\n",
    "     'criterion' : ['gini', 'entropy'],\n",
    "     'max_features' : ['auto', 'log2'],\n",
    "    }\n",
    "]\n",
    "\n",
    "bestEstimator = testModel(model=model, paramGrid=param_grid, X=X_train_entropy, y=y_train_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-short term memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbour (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classifier: KNeighborsClassifier\n",
      "Scoring: make_scorer(f1_score)\n",
      "K-fold times: 8 --- n-jobs: -1\n",
      "\n",
      "\n",
      "Best Params: {'weights': 'distance', 'n_neighbors': 5}\n",
      "Best Estimator: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='distance')\n",
      "0.6537853779922721 {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.654005283767055 {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.6548285821862858 {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.6549411385207313 {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.618348262959203 {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.6399826071668968 {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.602868384543845 {'weights': 'uniform', 'n_neighbors': 25}\n",
      "0.6061941398707827 {'weights': 'distance', 'n_neighbors': 25}\n",
      "Minutes taken:  7.2701422015825905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Create a parameter grid - here you specifiy which combinations you want to test\n",
    "param_grid = [\n",
    "        {'n_neighbors' : [3, 5, 10, 25],\n",
    "         'weights' : ['uniform', 'distance'],\n",
    "    }\n",
    "]\n",
    "\n",
    "bestEstimator = testModel(model=model, paramGrid=param_grid, X=X_train_entropy, y=y_train_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classifier: GradientBoostingClassifier\n",
      "Scoring: make_scorer(f1_score)\n",
      "K-fold times: 8 --- n-jobs: -1\n",
      "\n",
      "\n",
      "Best Params: {'loss': 'deviance', 'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "Best Estimator: GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "0.5020818395434242 {'loss': 'deviance', 'learning_rate': 0.001, 'n_estimators': 1000}\n",
      "0.4991345563346099 {'loss': 'exponential', 'learning_rate': 0.001, 'n_estimators': 1000}\n",
      "0.6198956389661714 {'loss': 'deviance', 'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.615112670167276 {'loss': 'exponential', 'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.6650755260313606 {'loss': 'deviance', 'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "0.6585085476876376 {'loss': 'exponential', 'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "Minutes taken:  103.06676442623139\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = [\n",
    "        {'learning_rate' : [0.001, 0.01, 0.1],\n",
    "         'loss' : ['deviance', 'exponential'],\n",
    "         'n_estimators' : [1000], # 1000 seems good \n",
    "    }\n",
    "]\n",
    "\n",
    "bestEstimator = testModel(model=model, paramGrid=param_grid, X=X_train_entropy, y=y_train_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classifier: AdaBoostClassifier\n",
      "Scoring: make_scorer(f1_score)\n",
      "K-fold times: 8 --- n-jobs: -1\n",
      "\n",
      "\n",
      "Best Params: {'learning_rate': 1.2, 'n_estimators': 2000}\n",
      "Best Estimator: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.2,\n",
      "                   n_estimators=2000, random_state=None)\n",
      "0.6814987904093085 {'learning_rate': 1, 'n_estimators': 500}\n",
      "0.679406349296515 {'learning_rate': 1, 'n_estimators': 1000}\n",
      "0.6877386966934965 {'learning_rate': 1, 'n_estimators': 2000}\n",
      "0.6891893546976744 {'learning_rate': 1.2, 'n_estimators': 500}\n",
      "0.6910805880717243 {'learning_rate': 1.2, 'n_estimators': 1000}\n",
      "0.7022789704709536 {'learning_rate': 1.2, 'n_estimators': 2000}\n",
      "Minutes taken:  66.19252619743347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create a model to test\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# Create a parameter grid - here you specifiy which combinations you want to test\n",
    "param_grid = [\n",
    "    {'n_estimators': [500, 1000, 2000],\n",
    "     'learning_rate' : [1, 1.2]\n",
    "    }\n",
    "]\n",
    "\n",
    "bestEstimator = testModel(model=model, paramGrid=param_grid, X=X_train_entropy, y=y_train_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classifier: MLPClassifier\n",
      "Scoring: make_scorer(f1_score)\n",
      "K-fold times: 8 --- n-jobs: -1\n",
      "\n",
      "\n",
      "Best Params: {'hidden_layer_sizes': (4, 100), 'learning_rate': 'constant', 'activation': 'relu', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "Best Estimator: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(4, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "0.656373329867982 {'hidden_layer_sizes': (2, 100), 'learning_rate': 'constant', 'activation': 'relu', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6354064922259919 {'hidden_layer_sizes': (2, 50), 'learning_rate': 'constant', 'activation': 'relu', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6596173085891588 {'hidden_layer_sizes': (2, 200), 'learning_rate': 'constant', 'activation': 'relu', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.666266871394257 {'hidden_layer_sizes': (4, 50), 'learning_rate': 'constant', 'activation': 'relu', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6869091565299595 {'hidden_layer_sizes': (4, 100), 'learning_rate': 'constant', 'activation': 'relu', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6625814114345603 {'hidden_layer_sizes': (2, 100), 'learning_rate': 'constant', 'activation': 'tanh', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6573710562666951 {'hidden_layer_sizes': (2, 50), 'learning_rate': 'constant', 'activation': 'tanh', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6855869604563838 {'hidden_layer_sizes': (2, 200), 'learning_rate': 'constant', 'activation': 'tanh', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6610187617524969 {'hidden_layer_sizes': (4, 50), 'learning_rate': 'constant', 'activation': 'tanh', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.684928111311977 {'hidden_layer_sizes': (4, 100), 'learning_rate': 'constant', 'activation': 'tanh', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6213792873763434 {'hidden_layer_sizes': (2, 100), 'learning_rate': 'constant', 'activation': 'logistic', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6055972114914372 {'hidden_layer_sizes': (2, 50), 'learning_rate': 'constant', 'activation': 'logistic', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6241305940026087 {'hidden_layer_sizes': (2, 200), 'learning_rate': 'constant', 'activation': 'logistic', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.6237301998041023 {'hidden_layer_sizes': (4, 50), 'learning_rate': 'constant', 'activation': 'logistic', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "0.632198244997211 {'hidden_layer_sizes': (4, 100), 'learning_rate': 'constant', 'activation': 'logistic', 'shuffle': True, 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
      "Minutes taken:  10.41994939247767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/venv/ml/lib/python3.5/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a model to test\n",
    "model = MLPClassifier()\n",
    "\n",
    "# Create a parameter grid - here you specifiy which combinations you want to test\n",
    "param_grid = [\n",
    "    {'hidden_layer_sizes': [(2, 100), (2, 50), (2, 200), (4, 50), (4, 100)],\n",
    "     'activation' : ['relu', 'tanh', 'logistic'],\n",
    "     'solver' : ['adam'],\n",
    "     'alpha' : [0.0001],\n",
    "     'learning_rate' : ['constant'],\n",
    "     'learning_rate_init' : [0.001],\n",
    "     'shuffle' : [True]\n",
    "    }\n",
    "]\n",
    "\n",
    "bestEstimator = testModel(model=model, paramGrid=param_grid, X=X_train_entropy, y=y_train_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
