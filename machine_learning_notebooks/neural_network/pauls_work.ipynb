{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Masterthesis\\thesis_eeg\\code\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# to enable local imports\n",
    "module_path = os.path.abspath('../../code')\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from machine_learning_load_data import loadOnlineEEGdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some online EEG Data\n",
    "eegData, freqData, entropyData = loadOnlineEEGdata(dirPath='../../../EEG_Data/eeg_data_online', splitData=True)\n",
    "\n",
    "X_train_eeg, y_train_eeg, X_test_eeg, y_test_eeg = eegData\n",
    "X_train_freq, y_train_freq, X_test_freq, y_test_freq = freqData\n",
    "X_train_entropy, y_train_entropy, X_test_entropy, y_test_entropy = entropyData\n",
    "\n",
    "# reshape\n",
    "X_train_freq = X_train_freq.reshape(X_train_freq.shape[0], X_train_freq.shape[2])\n",
    "X_test_freq = X_test_freq.reshape(X_test_freq.shape[0], X_test_freq.shape[2])\n",
    "\n",
    "X_train_entropy = X_train_entropy.reshape(X_train_entropy.shape[0], X_train_entropy.shape[2])\n",
    "X_test_entropy = X_test_entropy.reshape(X_test_entropy.shape[0], X_test_entropy.shape[2])\n",
    "\n",
    "\n",
    "##################\n",
    "# experiment data\n",
    "##################\n",
    "eegData_exp, freqData_exp, entropyData_exp = loadOnlineEEGdata(dirPath='../../../EEG_Data/muse_data', splitData=True)\n",
    "\n",
    "X_train_eeg_exp, y_train_eeg_exp, X_test_eeg_exp, y_test_eeg_exp = eegData_exp\n",
    "X_train_freq_exp, y_train_freq_exp, X_test_freq_exp, y_test_freq_exp = freqData_exp\n",
    "X_train_entropy_exp, y_train_entropy_exp, X_test_entropy_exp, y_test_entropy_exp = entropyData_exp\n",
    "\n",
    "# reshape\n",
    "X_train_freq_exp = X_train_freq_exp.reshape(X_train_freq_exp.shape[0], X_train_freq_exp.shape[2])\n",
    "X_test_freq_exp = X_test_freq_exp.reshape(X_test_freq_exp.shape[0], X_test_freq_exp.shape[2])\n",
    "\n",
    "X_train_entropy_exp = X_train_entropy_exp.reshape(X_train_entropy_exp.shape[0], X_train_entropy_exp.shape[2])\n",
    "X_test_entropy_exp = X_test_entropy_exp.reshape(X_test_entropy_exp.shape[0], X_test_entropy_exp.shape[2])\n",
    "\n",
    "#targetLabelsDict_exp = loadTargetLabelsTxt(filePath='../../EEG_Data/muse_data/target_labels.txt')\n",
    "#targetNames_exp = ['AWAKE ({})'.format(targetLabelsDict_exp['AWAKE']),\n",
    "#               'FATIGUE ({})'.format(targetLabelsDict_exp['FATIGUE'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainEvaluateNet(x_train, y_train, x_test, y_test):\n",
    "\n",
    "    #Convert data set to numpy array of type float32\n",
    "    #x_train = np.asarray(x_train, np.float32)\n",
    "    #y_train = np.asarray(y_train, np.float32)\n",
    "    #x_test = np.asarray(x_test, np.float32)\n",
    "    #y_test = np.asarray(y_test, np.float32)\n",
    "\n",
    "    #Number of neurons\n",
    "    neurons_num = int((2/3) * x_train.shape[2])\n",
    "\n",
    "    #Initialize neural net\n",
    "    #output of layer = keras.layers.Dense(number of neurons, activation function, name)(input of layer)\n",
    "    inputs = keras.Input(shape=(x_train.shape[1], x_train.shape[2]), name='input_points')\n",
    "    x = keras.layers.Dense(neurons_num, activation='relu', name='L1')(inputs)\n",
    "    x = keras.layers.Dense(neurons_num, activation='relu', name='L2')(x)\n",
    "    outputs = keras.layers.Dense(2, activation='softmax', name='output_point')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='fatigue_classifier')\n",
    "\n",
    "    #Set optimizer, loss function and metrics to track\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    #binary_crossentropy\n",
    "\n",
    "    #Summary of the neural net\n",
    "    #model.summary()\n",
    "    \n",
    "    #Train neural net\n",
    "    model.fit(x_train, y_train, epochs=3)\n",
    "\n",
    "    #Evaluate neural net\n",
    "    score = model.evaluate(x_test, y_test, verbose=verbose)\n",
    "    loss = score[0]\n",
    "    accuracy = score[1]\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', accuracy)\n",
    "    return (model, loss, accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEvaluateNet(x_train, y_train, x_test, y_test,batch_size=64, num_classes=2, epochs=5, verbose=0):\n",
    "\n",
    "    #Settings\n",
    "    neurons_num = int((2/3) * x_train.shape[2]) #Number of neurons\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    #Initialize neural net\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=10, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(Conv1D(64, kernel_size=1, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(neurons_num, activation='relu'))\n",
    "    model.add(Dense(neurons_num, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax', name='last_dense')) \n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    #Set optimizer, loss function and metrics to track\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(0.01), metrics=['accuracy'])\n",
    "    #model.compile(loss=keras.losses.squared_hinge, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "    #Summary of the neural net\n",
    "    #model.summary()\n",
    "    \n",
    "    #Train neural net\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=verbose,\n",
    "              validation_data=(x_test, y_test))\n",
    "    #         validation_split=0.2)\n",
    "\n",
    "    #Evaluate neural net\n",
    "    score = model.evaluate(x_test, y_test, verbose=verbose)\n",
    "    loss = score[0]\n",
    "    accuracy = score[1]\n",
    "    print('Test loss: {}'.format(loss))\n",
    "    print('Test accuracy: {}'.format(accuracy))\n",
    "    return (model, loss, accuracy)\n",
    "\n",
    "    #Predict best route\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEasyNet(x_train, y_train, x_test, y_test, batch_size=64, num_classes=2, epochs=5, verbose=0):\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    neurons_num = int((2/3) * x_train.shape[1]) #Number of neurons\n",
    "    \n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(neurons_num*2), input_dim=x_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(neurons_num, activation='relu'))\n",
    "    #model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(int(neurons_num/2), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax', name='last_dense'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    # compile the keras model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(0.01), metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    #Evaluate neural net\n",
    "    score = model.evaluate(x_test, y_test, verbose=verbose)\n",
    "    loss = score[0]\n",
    "    accuracy = score[1]\n",
    "    print('Test loss: {}'.format(loss))\n",
    "    print('Test accuracy: {}'.format(accuracy))\n",
    "    return (model, loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def train_lstm(x_train, y_train, x_test, y_test, batch_size=64, num_classes=2, epochs=5, verbose=0):\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    try:\n",
    "        n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
    "    except IndexError: \n",
    "        # reshape that...\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
    "        n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(\"n_timesteps: {} - n_features: {} - n_outputs: {}\".format(n_timesteps, n_features, n_outputs))\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    #_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    #Evaluate neural net\n",
    "    score = model.evaluate(x_test, y_test, verbose=verbose)\n",
    "    loss = score[0]\n",
    "    accuracy = score[1]\n",
    "    print('Test loss: {}'.format(loss))\n",
    "    print('Test accuracy: {}'.format(accuracy))\n",
    "    return (model, loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyNet(input_data, model):\n",
    "    prediction = model.predict([input_data]) \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrcis(statistics_data, title:str):\n",
    "    \n",
    "    # Define labels, positions, bar heights and error bar heights\n",
    "    x_pos = np.arange(len(statistics_data.keys()))\n",
    "    \n",
    "    # Define labels, positions, bar heights and error bar heights\n",
    "    labels = statistics_data.keys()\n",
    "    \n",
    "    loss = []\n",
    "    acc = []\n",
    "    \n",
    "    for key, data_dict in statistics_data.items():\n",
    "        \n",
    "        for data_source in statistics_data[key].keys():\n",
    "            loss.append(statistics_data[key][data_source]['loss'])\n",
    "            acc.append(statistics_data[key][data_source]['accuarcy'])\n",
    "            \n",
    "    print(\"Loss: {}\".format(loss))\n",
    "    print(\"Acc: {}\".format(acc))\n",
    "        \n",
    "    \n",
    "    # create plot\n",
    "    width = 0.2    \n",
    "    fig, ax = plt.subplots(figsize=(12,5))\n",
    "    plt.bar(x_pos, acc, width, label='accuarcy')\n",
    "    plt.bar(x_pos + width, loss, width, label='loss')\n",
    "    \n",
    "    \n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_xticks(x_pos + width)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title(title)\n",
    "    ax.yaxis.grid(True)\n",
    "    \n",
    "    \n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "    plt.legend(loc='best')\n",
    "    # Save the figure and show\n",
    "    save_fig(\"{}_metrics\".format(title.replace(\" \", \"_\")))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: [1.1378809221916728, 1.4110502578964943, 1.6079379791133506, 0.6988416079006393, 1.3613783563659698, 1.2214424970145565, 1.1481416922743601, 0.7456444809181055]\n",
      "Acc: [0.5902777910232544, 0.5589600801467896, 0.6387096643447876, 0.5778546929359436, 0.5694444179534912, 0.5366759300231934, 0.6279569864273071, 0.5640138387680054]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-287f74a8fc1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_metrcis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatsDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"asd\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-a824dfd0f8f4>\u001b[0m in \u001b[0;36mplot_metrcis\u001b[1;34m(statistics_data, title)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuarcy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2407\u001b[0m     return gca().bar(\n\u001b[0;32m   2408\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2409\u001b[1;33m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1563\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2340\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[0;32m   2341\u001b[0m             \u001b[1;31m# Make args iterable too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2342\u001b[1;33m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[0;32m   2343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2344\u001b[0m         \u001b[1;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;31m# consistently\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m     \u001b[1;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrcis(statsDict, title=\"asd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Easy Net\n",
      "Online Frequency Data\n",
      "Test loss: 1.1378809221916728\n",
      "Test accuracy: 0.5902777910232544\n",
      "Test loss: 1.4110502578964943\n",
      "Test accuracy: 0.5589600801467896\n",
      "Experiement Frequency Data\n",
      "Test loss: 1.6079379791133506\n",
      "Test accuracy: 0.6387096643447876\n",
      "Experiement Entropy Data\n",
      "Test loss: 0.6988416079006393\n",
      "Test accuracy: 0.5778546929359436\n",
      "Evaluating LSTM Net\n",
      "Online Frequency Data\n",
      "Test loss: 1.3613783563659698\n",
      "Test accuracy: 0.5694444179534912\n",
      "Test loss: 1.2214424970145565\n",
      "Test accuracy: 0.5366759300231934\n",
      "Experiement Frequency Data\n",
      "Test loss: 1.1481416922743601\n",
      "Test accuracy: 0.6279569864273071\n",
      "Experiement Entropy Data\n",
      "Test loss: 0.7456444809181055\n",
      "Test accuracy: 0.5640138387680054\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "netFunctionList = [(\"Easy Net\", trainEasyNet), (\"LSTM Net\", train_lstm)]\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "verbose = 0\n",
    "num_classes = 2\n",
    "\n",
    "statsDict = {}\n",
    "\n",
    "for net_name, function in netFunctionList:\n",
    "    print(\"Evaluating {}\".format(net_name))\n",
    "    \n",
    "    statsDict[net_name] = {}\n",
    "    \n",
    "    print(\"Online Frequency Data\")\n",
    "    model, loss, accuarcy = function(X_train_freq, y_train_freq, X_test_freq, y_test_freq,\n",
    "                                     epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    statsDict[net_name]['online_freq_data'] = {\"model\" : model, \"loss\" : loss, \"accuarcy\" : accuarcy}\n",
    "    \n",
    "    \n",
    "    model, loss, accuarcy = function(X_train_entropy, y_train_entropy, X_test_entropy, y_test_entropy,\n",
    "                                     epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    statsDict[net_name]['online_entropy_data'] = {\"model\" : model, \"loss\" : loss, \"accuarcy\" : accuarcy}\n",
    "    \n",
    "    print(\"Experiement Frequency Data\")\n",
    "    model, loss, accuarcy = function(X_train_freq_exp, y_train_freq_exp, X_test_freq_exp, y_test_freq_exp,\n",
    "                                     epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    statsDict[net_name]['experiment_freq_data'] = {\"model\" : model, \"loss\" : loss, \"accuarcy\" : accuarcy}\n",
    "    \n",
    "    print(\"Experiement Entropy Data\")\n",
    "    model, loss, accuarcy = function(X_train_entropy_exp, y_train_entropy_exp, X_test_entropy_exp, y_test_entropy_exp,\n",
    "                                     epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    statsDict[net_name]['experiment_entropy_data'] = {\"model\" : model, \"loss\" : loss, \"accuarcy\" : accuarcy}\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'online_freq_data': {'model': <keras.engine.sequential.Sequential at 0x258e5f60688>,\n",
       "  'loss': 1.1378809221916728,\n",
       "  'accuarcy': 0.5902777910232544},\n",
       " 'online_entropy_data': {'model': <keras.engine.sequential.Sequential at 0x258d362fa88>,\n",
       "  'loss': 1.4110502578964943,\n",
       "  'accuarcy': 0.5589600801467896},\n",
       " 'experiment_freq_data': {'model': <keras.engine.sequential.Sequential at 0x258cf176fc8>,\n",
       "  'loss': 1.6079379791133506,\n",
       "  'accuarcy': 0.6387096643447876},\n",
       " 'experiment_entropy_data': {'model': <keras.engine.sequential.Sequential at 0x258d3e5ad88>,\n",
       "  'loss': 0.6988416079006393,\n",
       "  'accuarcy': 0.5778546929359436}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsDict['Easy Net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1008/1008 [==============================] - 0s 471us/step - loss: 3.2995 - accuracy: 0.5258\n",
      "Epoch 2/10\n",
      "1008/1008 [==============================] - 0s 357us/step - loss: 0.6450 - accuracy: 0.6230\n",
      "Epoch 3/10\n",
      "1008/1008 [==============================] - 0s 330us/step - loss: 0.5557 - accuracy: 0.7222\n",
      "Epoch 4/10\n",
      "1008/1008 [==============================] - 0s 333us/step - loss: 0.4948 - accuracy: 0.7788\n",
      "Epoch 5/10\n",
      "1008/1008 [==============================] - 0s 337us/step - loss: 0.4586 - accuracy: 0.7956\n",
      "Epoch 6/10\n",
      "1008/1008 [==============================] - 0s 342us/step - loss: 0.3816 - accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "1008/1008 [==============================] - 0s 347us/step - loss: 0.3965 - accuracy: 0.8264\n",
      "Epoch 8/10\n",
      "1008/1008 [==============================] - 0s 333us/step - loss: 0.2886 - accuracy: 0.8730\n",
      "Epoch 9/10\n",
      "1008/1008 [==============================] - 0s 337us/step - loss: 0.3082 - accuracy: 0.8532\n",
      "Epoch 10/10\n",
      "1008/1008 [==============================] - 0s 372us/step - loss: 0.2579 - accuracy: 0.8919\n",
      "Test loss: 1.0882309201966833\n",
      "Test accuracy: 0.6041666865348816\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
