{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Masterthesis\\thesis_eeg\\code\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# to enable local imports\n",
    "module_path = os.path.abspath('../../code')\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from machine_learning_load_data import loadOnlineEEGdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Online EEG Data from ../../../EEG_Data/eeg_data_online ...\n",
      "EEG Data Shape:\n",
      "(5024, 512, 40) (5024,) (2154, 512, 40) (2154,)\n",
      "Freq Data Shape:\n",
      "(1008, 1, 1200) (1008,) (432, 1, 1200) (432,)\n",
      "Entropy Data Shape:\n",
      "(5024, 1, 200) (5024,) (2154, 1, 200) (2154,)\n"
     ]
    }
   ],
   "source": [
    "# Load some online EEG Data\n",
    "eegData, freqData, entropyData = loadOnlineEEGdata(dirPath='../../../EEG_Data/eeg_data_online', splitData=True)\n",
    "\n",
    "X_train_eeg, y_train_eeg, X_test_eeg, y_test_eeg = eegData\n",
    "X_train_freq, y_train_freq, X_test_freq, y_test_freq = freqData\n",
    "X_train_entropy, y_train_entropy, X_test_entropy, y_test_entropy = entropyData\n",
    "\n",
    "# reshape\n",
    "#X_train_freq = X_train_freq.reshape(X_train_freq.shape[0], X_train_freq.shape[2])\n",
    "#X_test_freq = X_test_freq.reshape(X_test_freq.shape[0], X_test_freq.shape[2])\n",
    "\n",
    "#X_train_entropy = X_train_entropy.reshape(X_train_entropy.shape[0], X_train_entropy.shape[2])\n",
    "#X_test_entropy = X_test_entropy.reshape(X_test_entropy.shape[0], X_test_entropy.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainEvaluateNet(x_train, y_train, x_test, y_test):\n",
    "\n",
    "    #Convert data set to numpy array of type float32\n",
    "    #x_train = np.asarray(x_train, np.float32)\n",
    "    #y_train = np.asarray(y_train, np.float32)\n",
    "    #x_test = np.asarray(x_test, np.float32)\n",
    "    #y_test = np.asarray(y_test, np.float32)\n",
    "\n",
    "    #Number of neurons\n",
    "    neurons_num = int((2/3) * x_train.shape[2])\n",
    "\n",
    "    #Initialize neural net\n",
    "    #output of layer = keras.layers.Dense(number of neurons, activation function, name)(input of layer)\n",
    "    inputs = keras.Input(shape=(x_train.shape[1], x_train.shape[2]), name='input_points')\n",
    "    x = keras.layers.Dense(neurons_num, activation='relu', name='L1')(inputs)\n",
    "    x = keras.layers.Dense(neurons_num, activation='relu', name='L2')(x)\n",
    "    outputs = keras.layers.Dense(2, activation='softmax', name='output_point')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='fatigue_classifier')\n",
    "\n",
    "    #Set optimizer, loss function and metrics to track\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    #binary_crossentropy\n",
    "\n",
    "    #Summary of the neural net\n",
    "    #model.summary()\n",
    "    \n",
    "    #Train neural net\n",
    "    model.fit(x_train, y_train, epochs=3)\n",
    "\n",
    "    #Evaluate neural net\n",
    "    model.evaluate(x_test, y_test)\n",
    "\n",
    "    #Predict best route\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDataSet(dataset, channels):\n",
    "    #converts the frequency dataset from (1008,1,1200) (samples, placeholder, channels + values) in (1008,40,30,1) (samples, channels, values, placeholder)\n",
    "    newdataset = np.zeros((int(dataset.shape[0]), int((dataset.shape[2]/channels)), int(channels), 1))\n",
    "    for sample in range(dataset.shape[0]):\n",
    "        for channel in range(0, dataset.shape[2], channels):\n",
    "            for values in range(channels):\n",
    "                newdataset[sample, int(channel/30), values, 0] = dataset[sample, 0, channel + values]\n",
    "    \n",
    "    newdataset = np.asarray(newdataset, np.float32)\n",
    "    return newdataset\n",
    "\n",
    "\n",
    "def TrainEvaluateNet(x_train, y_train, x_test, y_test):\n",
    "\n",
    "    #converting training dataset\n",
    "    x_train = convertDataSet(x_train, 30)\n",
    "    x_test = convertDataSet(x_test, 30)\n",
    "    \n",
    "    #Settings\n",
    "    batch_size = 64\n",
    "    num_classes = 2\n",
    "    epochs = 3\n",
    "    neurons_num = int((2/3) * x_train.shape[2]) #Number of neurons\n",
    "\n",
    "    #Initialize neural net\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3])))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(neurons_num*100, activation='relu'))\n",
    "    model.add(Dense(neurons_num*10, activation='relu'))\n",
    "    model.add(Dense(neurons_num, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes-1, activation='softmax', name='last_dense')) # 'softmax'\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    #Set optimizer, loss function and metrics to track\n",
    "    #model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "    model.compile(loss=keras.losses.squared_hinge, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "    #Summary of the neural net\n",
    "    #model.summary()\n",
    "    \n",
    "    #Train neural net\n",
    "    model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)\n",
    "\n",
    "    #Evaluate neural net\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    #Predict best route\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 1, 1200)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_53 (Conv2D)           (None, 38, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 36, 26, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 14976)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2000)              29954000  \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 200)               400200    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 20)                4020      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "last_dense (Dense)           (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 30,377,057\n",
      "Trainable params: 30,377,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 806 samples, validate on 202 samples\n",
      "Epoch 1/3\n",
      "806/806 [==============================] - 8s 10ms/step - loss: 2.0844 - accuracy: 0.4789 - val_loss: 2.1386 - val_accuracy: 0.4653\n",
      "Epoch 2/3\n",
      "806/806 [==============================] - 7s 9ms/step - loss: 2.0844 - accuracy: 0.4789 - val_loss: 2.1386 - val_accuracy: 0.4653\n",
      "Epoch 3/3\n",
      "806/806 [==============================] - 7s 9ms/step - loss: 2.0844 - accuracy: 0.4789 - val_loss: 2.1386 - val_accuracy: 0.4653\n",
      "Test loss: 1.7777777777777777\n",
      "Test accuracy: 0.5555555820465088\n"
     ]
    }
   ],
   "source": [
    "def ApplyNet(input_data, model):\n",
    "    prediction = model.predict([input_data]) \n",
    "    return prediction\n",
    "\n",
    "model = TrainEvaluateNet(X_train_freq, y_train_freq, X_test_freq, y_test_freq)\n",
    "#ApplyNet(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 1 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-8c380558ec71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainEvaluateNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_entropy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#ApplyNet(model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-4aefa7330584>\u001b[0m in \u001b[0;36mTrainEvaluateNet\u001b[1;34m(x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#converting training dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-4aefa7330584>\u001b[0m in \u001b[0;36mconvertDataSet\u001b[1;34m(dataset, channels)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                 \u001b[0mnewdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mnewdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 6 is out of bounds for axis 1 with size 6"
     ]
    }
   ],
   "source": [
    "model = TrainEvaluateNet(X_train_entropy, y_train_entropy, X_test_entropy, y_test_entropy)\n",
    "#ApplyNet(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
