{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to evalute each Model in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nvidia/masterthesis/thesis_eeg/code\n",
      "argument should be a path or str object, not <class 'NoneType'>\n",
      "Saving images to: ../images\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# to enable local imports\n",
    "module_path = os.path.abspath('../code')\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "    \n",
    "from pathlib import Path\n",
    "try:\n",
    "    try:\n",
    "        json_path = (Path(os.getenv('LOCALAPPDATA'))/'Dropbox'/'info.json').resolve()\n",
    "    except FileNotFoundError:\n",
    "        json_path = (Path(os.getenv('APPDATA'))/'Dropbox'/'info.json').resolve()\n",
    "\n",
    "    with open(str(json_path)) as f:\n",
    "        j = json.load(f)\n",
    "\n",
    "    personal_dbox_path = Path(j['personal']['path'])\n",
    "    # Save the images directly into the dropbox where the overleaf document is stored\n",
    "    IMAGES_PATH = os.path.join(str(personal_dbox_path), 'Apps', 'Overleaf', 'Masterthesis_Paper', 'images')\n",
    "\n",
    "except Exception as e:\n",
    "    IMAGES_PATH = \"../images\"\n",
    "    print(e)\n",
    "    \n",
    "print(\"Saving images to: {}\".format(IMAGES_PATH))\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution, bbox_inches='tight')\n",
    "\n",
    "from machine_learning_load_data import loadOnlineEEGdata\n",
    "from utils import loadTargetLabelsTxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Online EEG Data from ../../EEG_Data/eeg_data_online ...\n",
      "EEG Data Shape:\n",
      "(5024, 512, 40) (5024,) (2154, 512, 40) (2154,)\n",
      "Freq Data Shape:\n",
      "(1008, 1, 1200) (1008,) (432, 1, 1200) (432,)\n",
      "Entropy Data Shape:\n",
      "(5024, 1, 200) (5024,) (2154, 1, 200) (2154,)\n",
      "Loading Online EEG Data from ../../EEG_Data/muse_data ...\n",
      "EEG Data Shape:\n",
      "(3306, 512, 4) (3306,) (1418, 512, 4) (1418,)\n",
      "Freq Data Shape:\n",
      "(665, 1, 120) (665,) (285, 1, 120) (285,)\n",
      "Entropy Data Shape:\n",
      "(3306, 1, 20) (3306,) (1418, 1, 20) (1418,)\n"
     ]
    }
   ],
   "source": [
    "# Load some online EEG Data\n",
    "\n",
    "##################\n",
    "# online eeg data\n",
    "##################\n",
    "eegData, freqData, entropyData = loadOnlineEEGdata(dirPath='../../EEG_Data/eeg_data_online', splitData=True)\n",
    "\n",
    "X_train_eeg, y_train_eeg, X_test_eeg, y_test_eeg = eegData\n",
    "X_train_freq, y_train_freq, X_test_freq, y_test_freq = freqData\n",
    "X_train_entropy, y_train_entropy, X_test_entropy, y_test_entropy = entropyData\n",
    "\n",
    "# reshape\n",
    "X_train_freq = X_train_freq.reshape(X_train_freq.shape[0], X_train_freq.shape[2])\n",
    "X_test_freq = X_test_freq.reshape(X_test_freq.shape[0], X_test_freq.shape[2])\n",
    "\n",
    "X_train_entropy = X_train_entropy.reshape(X_train_entropy.shape[0], X_train_entropy.shape[2])\n",
    "X_test_entropy = X_test_entropy.reshape(X_test_entropy.shape[0], X_test_entropy.shape[2])\n",
    "\n",
    "targetLabelsDict = loadTargetLabelsTxt(filePath='../../EEG_Data/eeg_data_online/target_labels.txt')\n",
    "targetNames = ['Fatigue ({})'.format(targetLabelsDict['FATIGUE']),\n",
    "               'Normal ({})'.format(targetLabelsDict['NORMAL'])]\n",
    "\n",
    "\n",
    "##################\n",
    "# experiment data\n",
    "##################\n",
    "eegData_exp, freqData_exp, entropyData_exp = loadOnlineEEGdata(dirPath='../../EEG_Data/muse_data', splitData=True)\n",
    "\n",
    "X_train_eeg_exp, y_train_eeg_exp, X_test_eeg_exp, y_test_eeg_exp = eegData_exp\n",
    "X_train_freq_exp, y_train_freq_exp, X_test_freq_exp, y_test_freq_exp = freqData_exp\n",
    "X_train_entropy_exp, y_train_entropy_exp, X_test_entropy_exp, y_test_entropy_exp = entropyData_exp\n",
    "\n",
    "# reshape\n",
    "X_train_freq_exp = X_train_freq_exp.reshape(X_train_freq_exp.shape[0], X_train_freq_exp.shape[2])\n",
    "X_test_freq_exp = X_test_freq_exp.reshape(X_test_freq_exp.shape[0], X_test_freq_exp.shape[2])\n",
    "\n",
    "X_train_entropy_exp = X_train_entropy_exp.reshape(X_train_entropy_exp.shape[0], X_train_entropy_exp.shape[2])\n",
    "X_test_entropy_exp = X_test_entropy_exp.reshape(X_test_entropy_exp.shape[0], X_test_entropy_exp.shape[2])\n",
    "\n",
    "targetLabelsDict_exp = loadTargetLabelsTxt(filePath='../../EEG_Data/muse_data/target_labels.txt')\n",
    "targetNames_exp = ['AWAKE ({})'.format(targetLabelsDict_exp['AWAKE']),\n",
    "               'FATIGUE ({})'.format(targetLabelsDict_exp['FATIGUE'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to evalute a Model (maybe move into a .py file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "f1_scorer = make_scorer(f1_score) \n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
    "    plt.grid(True)   \n",
    "\n",
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.title(\"Precision versus recall\")\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.grid(True)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    \n",
    "    plt.title(\"Precision versus recall - Threshold Plot\")\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.legend(loc=\"center right\", fontsize=16)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.grid(True)      \n",
    "\n",
    "\n",
    "# Create a model\n",
    "def evaluateModel(model,X_train, y_train, X_test=None, y_test=None, kfoldTimes=8, n_jobs=-1):\n",
    "    \n",
    "    print(\"Model: {}\".format(model))\n",
    "    \n",
    "    # generate cross val score\n",
    "    kfoldTimes = kfoldTimes\n",
    "    print(\"Calculating cross val scores...\")\n",
    "    accuaries = cross_val_score(model, X_train, y_train, cv=kfoldTimes, scoring=f1_scorer, n_jobs=n_jobs)\n",
    "    print(\"Cross val scores (Accuracies):\")\n",
    "    for i in range(0, len(accuaries)):\n",
    "        print(\" Fold {fold}: {acc}\".format(fold=i+1, acc=accuaries[i]))\n",
    "\n",
    "    # make predictions with the model\n",
    "    print(\"\\nCaclulating cross val predictions...\")\n",
    "    y_train_pred = cross_val_predict(model, X_train, y_train, cv=kfoldTimes, n_jobs=n_jobs)\n",
    "\n",
    "\n",
    "    svm_confusionMatrix = confusion_matrix(y_train, y_train_pred)\n",
    "    print(\"\"\"\\nConfusion Matrix\\n------------------------\n",
    "    True Negative:   {tn} - False Positive: {fp}\n",
    "    False Negatives: {fn} - True positive:  {tp}\"\"\".format(tn=svm_confusionMatrix[0][0],\n",
    "                                                           fp=svm_confusionMatrix[0][1],\n",
    "                                                           fn=svm_confusionMatrix[1][0],\n",
    "                                                           tp=svm_confusionMatrix[1][1]))\n",
    "\n",
    "    print(\"----------------------\")\n",
    "    print(\"Precision: {} \".format(precision_score(y_train, y_train_pred)))\n",
    "    print(\"Recall:    {}\".format(recall_score(y_train, y_train_pred)))\n",
    "    print(\"F1 Score:  {}\".format(f1_score(y_train, y_train_pred)))\n",
    "    \n",
    "    # Calculate and plot the precion-recall tradeoff\n",
    "    model.fit(X_train, y_train)\n",
    "    y_score = model.decision_function(X_train)\n",
    "    average_precision = average_precision_score(y_train, y_score)\n",
    "    print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "    \n",
    "    disp = plot_precision_recall_curve(model, X_train, y_train)\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "    \n",
    "    \n",
    "    # Calculate and plot precision vs. recall - threshold plot\n",
    "    y_scores_dec_func = cross_val_predict(model, X_train, y_train, cv=kfoldTimes, method=\"decision_function\", n_jobs=n_jobs)\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores_dec_func)\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "    \n",
    "    # Plot precision vs. recall directly against each other\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    \n",
    "    \n",
    "    # Calculate and plot the ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_scores_dec_func)\n",
    "    plt.figure(figsize=(8, 6)) \n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    \n",
    "    \n",
    "    # Compare to another model\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    y_probas_forest = cross_val_predict(forest_clf, X_train, y_train, cv=kfoldTimes, method=\"predict_proba\", n_jobs=n_jobs)\n",
    "    \n",
    "    y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n",
    "    fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train, y_scores_forest)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"SVM\")\n",
    "    plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"lower right\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=5, gamma='scale', kernel='poly',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Calculating cross val scores...\n",
      "Cross val scores (Accuracies):\n",
      " Fold 1: 0.5957446808510638\n",
      " Fold 2: 0.7002398081534772\n",
      " Fold 3: 0.7353760445682451\n",
      " Fold 4: 0.7109974424552429\n",
      " Fold 5: 0.735632183908046\n",
      " Fold 6: 0.8090452261306533\n",
      " Fold 7: 0.7210031347962381\n",
      " Fold 8: 0.6991404011461317\n",
      "\n",
      "Caclulating cross val predictions...\n"
     ]
    }
   ],
   "source": [
    "# good model\n",
    "goodModel = svm.SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=5, gamma='scale', kernel='poly',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "\n",
    "#simpleModel = svm.SVC(kernel='rbf', gamma=0.3, C=1.0)\n",
    "\n",
    "\n",
    "#evaluateModel(model=goodModel,\n",
    "#              X_train=X_train_freq_exp,\n",
    "#              y_train=y_train_freq_exp,\n",
    "#              X_test=X_test_freq_exp,\n",
    "#              y_test=y_test_freq_exp)\n",
    "\n",
    "evaluateModel(model=goodModel,\n",
    "              X_train=X_train_entropy_exp,\n",
    "              y_train=y_train_entropy_exp,\n",
    "              X_test=X_test_entropy_exp,\n",
    "              y_test=y_test_entropy_exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
